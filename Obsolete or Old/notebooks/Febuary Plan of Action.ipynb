{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan for development directions for VE DM project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current state of play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the most basic scenario working, let us outline the directions unexplored as well as the achievements already present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On one hand, DeepMoD has been successful for finding the correct terms and coefficients for:\n",
    "\n",
    "- a stress input\n",
    "\n",
    "- a first order problem with second order terms present\n",
    "\n",
    "- with relatively few data points (500)\n",
    "\n",
    "- with a successfully working so far thresholding condition of scaled < 0.15\n",
    "\n",
    "- with a decay time roughly of the same size as the time period of the input data (~15 seconds)\n",
    "\n",
    "- with the input data in the form of a single frequency sinc curve\n",
    "\n",
    "- with the equillibrium spring arm weighted down compared to viscous arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, we have not explored how well DeepMoD will cope with:\n",
    "\n",
    "- Having two (or more) decay terms present\n",
    "\n",
    "- Having the decay terms present that are not similar to the time period of the curve.\n",
    "\n",
    "- Having decay terms present that are weighted more or less strongly than the other terms relatively (E_mods constitute weighting)\n",
    "\n",
    "- Having noise present and when so, differing degrees of it.\n",
    "\n",
    "- Having a sampling rate that is less frequent than the oscillation rate of the data\n",
    "\n",
    "- Having a sampling rate that is less frequent than the frequency of the model decay constants.\n",
    "\n",
    "- simpler input data forms (does sinc beat sine for same frequency?)\n",
    "\n",
    "- more complex input data forms (multiple frequencies - I'm, thinking Fourier style addition of frequencies....)\n",
    "\n",
    "- having third and higher order terms present even with only a first order problem.\n",
    "\n",
    "- universal differences in time scales (both decay constants of model and input data kept the same relative to each other)\n",
    "\n",
    "- Having more terms that need to be thresholded out of existence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to this, I have been testing how DeepMoD handles different time decays in a 1st order problem setting. For a sinc curve with time period of ~13 seconds, DeepMoD has successfully run and found terms and coeffs for problems with time decays of 5 - 15 seconds but not outside of that. Amplitude of sinc is always 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: independantly understand the affects of varying any one parameter at a time. This will give a good understanding of the current limitations of the implementation and give clues about how best to improve where the limitations are most severe.\n",
    "\n",
    "Second: use the insight gained to see if I can improve the performance.\n",
    "\n",
    "I will approch the directions in this order:\n",
    "\n",
    "1. Vary decay constant (some preliminary experimentation already done)\n",
    "\n",
    "2. Increase the number of higher order terms to be eliminated during thresholding.\n",
    "\n",
    "3. Trying 2nd and higher order problems with easy constants\n",
    "\n",
    "4. Vary equillibrium spring constant\n",
    "\n",
    "5. Vary decay weighting modulus\n",
    "\n",
    "6. Adding in different levels of noise\n",
    "\n",
    "7. Changing the universal time range for the data to be active in. Keep all constants affecting time-dependant performance the same relative to each other.\n",
    "\n",
    "8. (without random subsampling) having very low sampling rates\n",
    "\n",
    "9. Trying alternative functional forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General themes of investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All testing will build off a working base context wth only one parameter varied.\n",
    "\n",
    "This base set up will involve:\n",
    "\n",
    "- Stress always as the input (analytically described) variable\n",
    "\n",
    "- A sinc curve of rotational frequency 1, and so time period of $2\\pi$ and max amplitude 1 as input\n",
    "\n",
    "- A first order Kelvin Model with data generated using Boltzmann superposition integrals, with model parameters of $E_0 = 5$, $E_1 = 1$ and $\\eta_1 = 2\\pi$ (therefore $\\tau_1 = 2\\pi$).\n",
    "\n",
    "- No noise\n",
    "\n",
    "- 1000 randomly sampled points from a data set originally synthesised with 5000 points.\n",
    "\n",
    "- Data generated for 20 second. This means an average sampling rate of 50 data points / second after sub-sampling.\n",
    "\n",
    "- Will run with a lr of 0.001\n",
    "\n",
    "- Will run for 30001 epochs before thresholding. I will then run simply for 5000 more epochs after, as the constants settle very quickly by this point if the right ones have been chosen.\n",
    "\n",
    "- I will use a network with 4 layers of 30 neurons.\n",
    "\n",
    "- I will keep the default lambda of $10^{-5}$\n",
    "\n",
    "- I will force all coeffs to always be initialised at positive values.\n",
    "\n",
    "- I will ask DeepMoD to calculate up to second order derivatives, so that it has the opportunity to prove it can eliminate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will implement the below rough protocol:\n",
    "\n",
    "1. Loop through the variation of a single parameter.\n",
    "\n",
    "2. Do this 3 times for each condition to check for consistency or sensitivity to random initialisation (differentiation weak and strong success).\n",
    "    (is this needed?)\n",
    "\n",
    "3. Record the error compared to the correct coefficients in each case + other data (see comments).\n",
    "\n",
    "4. Graph success robustness to see where the limitations are currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary decay constant from $16\\pi$ to $\\pi/4$ (8x lower, 8x higher than time period), halving each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the number of extra derivatives in library from up to 2nd order, 3rd order, and 4th order, all for  a 1st order actual problem still."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have done some experimentation with branches that are similar to each other and noticed empirically as well as from the mathematical treatment that branches that have the same decay constant are indistinguishable from a single branch with a single decay constant.\n",
    "\n",
    "I will test both a 2nd order problem and a third, I do not anticipate any chance of success beyond for now.\n",
    "\n",
    "I will try a 2nd branch branch with parameters:\n",
    "\n",
    "$\n",
    "E_2 = 1, \\eta_2 = 4\\pi, (\\tau_2 = 4\\pi)\n",
    "$\n",
    "\n",
    "$\n",
    "E_2 = 1, \\eta_2 = 8\\pi, (\\tau_2 = 8\\pi)\n",
    "$\n",
    "\n",
    "$\n",
    "E_2 = 1, \\eta_2 = \\pi, (\\tau_2 = \\pi)\n",
    "$\n",
    "\n",
    "$\n",
    "E_2 = 1, \\eta_2 = \\pi/2, (\\tau_2 = \\pi/2)\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have kept $E_2 = E_1$ as I want both decays to be equally weighted in this test. It is difficult to predict the interaction betwen the model paramters in the two branches to give DeepMoD thie best shot, but this simple scenario seems a good place to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the 3rd branch, I will mostly use the same options, but I will see how this second branch goes to decide what will be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary equillibrium modulus from 40 to $5/8$ (8x lower, 8x higher than reference), halving each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary viscosity associated modulus from 8 to $1/8$ (8x lower, 8x higher than reference), halving each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use noise scaled to different percentasges of the standard deviation of the data.\n",
    "\n",
    "These percentages can be investigated in 'money steps', ie:\n",
    "\n",
    "1%, 2%, 5%, 10%, 20%, 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system seemed to struggle when I dropped both the time period of the sinc curve and the decay constant in the single branch to $\\pi/10$. Motivated by this, I would like to understand the range in which the constants can be found. The only thing I can think of that could cause this is that the absolute magnitude of the derivatives became larger, and this could have made scaling tricky.\n",
    "\n",
    "The time periods I will examine will be from $\\pi/4$ to $16\\pi$, 8x higher and lower than the known working condition, and I will double each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will define the sampling rates to test with reference to the characteristic time period of the decay and oscillation frequency (which are for now the same) of $2\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore I will try a sampling rate of $16/\\pi$ /s to $1/\\pi$ /s (Nyquist frequency limit), halving each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full time range of 20 seconds, this will correspond to 102, 51, 26, 13, 7 data points, which are all half each other but rounded up always."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will test:\n",
    "\n",
    "- a pseudo-sinc function where the amplitude decay is modified\n",
    "\n",
    "- a sine function of the same rotational frequency (1)\n",
    "\n",
    "- summation of 3 exponential decays at decay constants of $\\pi$, $2\\pi$ (matching initial time period) and $4\\pi$, weighted equally. This is an initial guess, depending on the capabilities of DeepMoD observed in earlier tests, these values may change. The point, however, is to see what is the more tractable problem for DeepMoD, so hopefully the performance will be different to the earlier tests anyway...\n",
    "\n",
    "- summation of 3 sine curves, with time periods matching the above decay constants.\n",
    "\n",
    "- summation of 3 sinc curves, also matching.\n",
    "\n",
    "- continuous distribution of frequencies to produce wave packet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a notebook already with the flow of varying I think at least most of these parameters and running DeepMoD but....\n",
    "\n",
    "- I will need to think of and design a flow for saving the relevant results of each test. These results should include (do you agree?):\n",
    "    - The target coeffs\n",
    "    - The actual coeffs arrived at\n",
    "    - the sparsity mask\n",
    "    - The average error in the coefficents\n",
    "    - a binary decision on success or failure.\n",
    "    - the network prediction data (strain)\n",
    "    - the network target data (strain)\n",
    "    - the time series data and stress series data\n",
    "    - the conditions of the test, stating the varied parameter and its value.\n",
    "    - The repeat (all tests done 3 times)\n",
    "\n",
    "\n",
    "- I will perhaps be able to produce bar graphs of the key data points, ie, success and accuracy for each varied parameter. I imagine this will not take very long to replicate, once I figure out a nice way which will be consistant.\n",
    "\n",
    "- This is going to take a long time. It will take time to:\n",
    "    - run all of the DeepMoD tests, at up to 35000 epochs each.\n",
    "    - design the system for saving all the relevant data in a format that makes sense.\n",
    "\n",
    "Hopefully the graphing doesn't count as a time cost as I can do that whilst it is all running, but I will need to understand how I am going to save the data before I start."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
