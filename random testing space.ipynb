{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cedd7ac36334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[[0], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-dc751f2bf219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 4), dtype=torch.int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((x[0, [0]], x[0, [2]]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((x[:, 0:2], x[:, 2:]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((x, x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3],\n",
       "        [4, 4]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12], [13,14,15,16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1],\n",
       "        [ 5],\n",
       "        [ 9],\n",
       "        [13]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((z[:, [0]], z[:, 2:]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  3,  4],\n",
       "        [ 5,  7,  8],\n",
       "        [ 9, 11, 12],\n",
       "        [13, 15, 16]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((z[:, [0]], z[:, 4:]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1],\n",
       "        [ 5],\n",
       "        [ 9],\n",
       "        [13]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_trial = {'bleep': 'blop', 'ping':'pong'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'baa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-682dcdd4f358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'baa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'baa'"
     ]
    }
   ],
   "source": [
    "dict_trial['baa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('baa', 'default')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-a256beeb817a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdict_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'baa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pong'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('baa', 'default')"
     ]
    }
   ],
   "source": [
    "if dict_trial['baa', 'default'] == 'pong':\n",
    "    print('Here')\n",
    "else:\n",
    "    print('not here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not here\n"
     ]
    }
   ],
   "source": [
    "if dict_trial.get('baa', None):\n",
    "    print('Here')\n",
    "else:\n",
    "    print('not here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, -1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [abs(value) for value in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try 'quotes'\n"
     ]
    }
   ],
   "source": [
    "print('try \\'quotes\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1, 2], [3, 4], [5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=y[:, [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4],\n",
       "        [6]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=y[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4],\n",
       "        [6]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not here\n"
     ]
    }
   ],
   "source": [
    "if 0:\n",
    "    print('here')\n",
    "else:\n",
    "    print('not here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.tensor([1, 1, 0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3, 4])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(z)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.remove(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-64f9957e5fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "x.remove(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-1dd538a4d846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "y.remove(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n"
     ]
    }
   ],
   "source": [
    "if 2 in y:\n",
    "    print('Here')\n",
    "else:\n",
    "    print('not here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'Input_Type': 'Strai'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not here\n"
     ]
    }
   ],
   "source": [
    "if a.get('Input_Type', None) == ('Strain' or 'Stress'):\n",
    "    print('Here')\n",
    "else:\n",
    "    print('not here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eval_Array_From_Expression(Input_Value_Array, Symbol_Variable, Symbolic_Expression):\n",
    "    \n",
    "    try:\n",
    "        raise\n",
    "        Eval_Func = sp.lambdify(Symbol_Variable, Symbolic_Expression)\n",
    "        Result_Array = Eval_Func(Input_Value_Array)\n",
    "        if len(Result_Array) != len(Input_Value_Array):\n",
    "            raise\n",
    "    except:\n",
    "        Result_Array = np.array([])\n",
    "        print(Result_Array)\n",
    "        print(Input_Value_Array)\n",
    "        print(type(Input_Value_Array))\n",
    "        for Input_Value in Input_Value_Array:\n",
    "            print(Input_Value)\n",
    "            print(type(Input_Value))\n",
    "            Result_Array = np.append(Result_Array, float(Symbolic_Expression.evalf(subs={Symbol_Variable: Input_Value})))\n",
    "        \n",
    "        print(type(Input_Value_Array))\n",
    "        print(type(Result_Array))\n",
    "        print(type(Result_Array[0]))\n",
    "        if type(Input_Value_Array) is torch.Tensor:\n",
    "            print('took bad method and hit numpy place')\n",
    "            print(Result_Array)\n",
    "            Result_Array = torch.tensor(Result_Array)\n",
    "            print(Result_Array)\n",
    "    \n",
    "    return Result_Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sym.symbols('t', real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0.1], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000], requires_grad=True)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "tensor([0.2000], grad_fn=<MulBackward0>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.2000, grad_fn=<SelectBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float64'>\n",
      "took bad method and hit numpy place\n",
      "[0.19866933]\n",
      "tensor([0.1987], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = Eval_Array_From_Expression(b, t, sym.sin(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84147098]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8415]], dtype=torch.float64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good method\n"
     ]
    }
   ],
   "source": [
    "x = Eval_Array_From_Expression(torch.tensor([[1.]]), t, sym.sin(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8415]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderbrandon-bravo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8415]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([1,2,3,4,5], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Eval_Array_From_Expression(y, t, sym.sin(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841470984807897, 0.909297426825682, 0.141120008059867,\n",
       "       -0.756802495307928, -0.958924274663138], dtype=object)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Eval_Array_From_Expression(y.detach(), t, sym.sin(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841470984807897, 0.909297426825682, 0.141120008059867,\n",
       "       -0.756802495307928, -0.958924274663138], dtype=object)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(np.array([1,2,3,4,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(torch.tensor([1,2,3,4,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sympy.core.evalf in sympy.core:\n",
      "\n",
      "NAME\n",
      "    sympy.core.evalf\n",
      "\n",
      "DESCRIPTION\n",
      "    Adaptive numerical evaluation of SymPy expressions, using mpmath\n",
      "    for mathematical functions.\n",
      "\n",
      "CLASSES\n",
      "    builtins.ArithmeticError(builtins.Exception)\n",
      "        PrecisionExhausted\n",
      "    builtins.object\n",
      "        EvalfMixin\n",
      "    \n",
      "    class EvalfMixin(builtins.object)\n",
      "     |  Mixin class adding evalf capabililty.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  evalf(self, n=15, subs=None, maxn=100, chop=False, strict=False, quad=None, verbose=False)\n",
      "     |      Evaluate the given formula to an accuracy of n digits.\n",
      "     |      Optional keyword arguments:\n",
      "     |      \n",
      "     |          subs=<dict>\n",
      "     |              Substitute numerical values for symbols, e.g.\n",
      "     |              subs={x:3, y:1+pi}. The substitutions must be given as a\n",
      "     |              dictionary.\n",
      "     |      \n",
      "     |          maxn=<integer>\n",
      "     |              Allow a maximum temporary working precision of maxn digits\n",
      "     |              (default=100)\n",
      "     |      \n",
      "     |          chop=<bool>\n",
      "     |              Replace tiny real or imaginary parts in subresults\n",
      "     |              by exact zeros (default=False)\n",
      "     |      \n",
      "     |          strict=<bool>\n",
      "     |              Raise PrecisionExhausted if any subresult fails to evaluate\n",
      "     |              to full accuracy, given the available maxprec\n",
      "     |              (default=False)\n",
      "     |      \n",
      "     |          quad=<str>\n",
      "     |              Choose algorithm for numerical quadrature. By default,\n",
      "     |              tanh-sinh quadrature is used. For oscillatory\n",
      "     |              integrals on an infinite interval, try quad='osc'.\n",
      "     |      \n",
      "     |          verbose=<bool>\n",
      "     |              Print debug information (default=False)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      =====\n",
      "     |      \n",
      "     |      When Floats are naively substituted into an expression, precision errors\n",
      "     |      may adversely affect the result. For example, adding 1e16 (a Float) to 1\n",
      "     |      will truncate to 1e16; if 1e16 is then subtracted, the result will be 0.\n",
      "     |      That is exactly what happens in the following:\n",
      "     |      \n",
      "     |      >>> from sympy.abc import x, y, z\n",
      "     |      >>> values = {x: 1e16, y: 1, z: 1e16}\n",
      "     |      >>> (x + y - z).subs(values)\n",
      "     |      0\n",
      "     |      \n",
      "     |      Using the subs argument for evalf is the accurate way to evaluate such an\n",
      "     |      expression:\n",
      "     |      \n",
      "     |      >>> (x + y - z).evalf(subs=values)\n",
      "     |      1.00000000000000\n",
      "     |  \n",
      "     |  n = evalf(self, n=15, subs=None, maxn=100, chop=False, strict=False, quad=None, verbose=False)\n",
      "    \n",
      "    class PrecisionExhausted(builtins.ArithmeticError)\n",
      "     |  Base class for arithmetic errors.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PrecisionExhausted\n",
      "     |      builtins.ArithmeticError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.ArithmeticError:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.ArithmeticError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    MPZ = mpz(...)\n",
      "        mpz() -> mpz(0)\n",
      "        \n",
      "             If no argument is given, return mpz(0).\n",
      "        \n",
      "        mpz(n) -> mpz\n",
      "        \n",
      "             Return an 'mpz' object with a numeric value 'n' (truncating n\n",
      "             to its integer part if it's a Fraction, 'mpq', Decimal, float\n",
      "             or 'mpfr').\n",
      "        \n",
      "        mpz(s[, base=0]):\n",
      "        \n",
      "             Return an 'mpz' object from a string 's' made of digits in the\n",
      "             given base.  If base=0, binary, octal, or hex Python strings\n",
      "             are recognized by leading 0b, 0o, or 0x characters, otherwise\n",
      "             the string is assumed to be decimal. Values for base can range\n",
      "             between 2 and 62.\n",
      "    \n",
      "    N(x, n=15, **options)\n",
      "        Calls x.evalf(n, \\*\\*options).\n",
      "        \n",
      "        Both .n() and N() are equivalent to .evalf(); use the one that you like better.\n",
      "        See also the docstring of .evalf() for information on the options.\n",
      "        \n",
      "        Examples\n",
      "        ========\n",
      "        \n",
      "        >>> from sympy import Sum, oo, N\n",
      "        >>> from sympy.abc import k\n",
      "        >>> Sum(1/k**k, (k, 1, oo))\n",
      "        Sum(k**(-k), (k, 1, oo))\n",
      "        >>> N(_, 4)\n",
      "        1.291\n",
      "    \n",
      "    add_terms(terms, prec, target_prec)\n",
      "        Helper for evalf_add. Adds a list of (mpfval, accuracy) terms.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        \n",
      "        - None, None if there are no non-zero terms;\n",
      "        - terms[0] if there is only 1 term;\n",
      "        - scaled_zero if the sum of the terms produces a zero by cancellation\n",
      "          e.g. mpfs representing 1 and -1 would produce a scaled zero which need\n",
      "          special handling since they are not actually zero and they are purposely\n",
      "          malformed to ensure that they can't be used in anything but accuracy\n",
      "          calculations;\n",
      "        - a tuple that is scaled to target_prec that corresponds to the\n",
      "          sum of the terms.\n",
      "        \n",
      "        The returned mpf tuple will be normalized to target_prec; the input\n",
      "        prec is used to define the working precision.\n",
      "        \n",
      "        XXX explain why this is needed and why one can't just loop using mpf_add\n",
      "    \n",
      "    as_mpmath(x, prec, options)\n",
      "    \n",
      "    bitcount(n)\n",
      "        Return smallest integer, b, such that |n|/2**b < 1.\n",
      "    \n",
      "    check_convergence(numer, denom, n)\n",
      "        Returns (h, g, p) where\n",
      "        -- h is:\n",
      "            > 0 for convergence of rate 1/factorial(n)**h\n",
      "            < 0 for divergence of rate factorial(n)**(-h)\n",
      "            = 0 for geometric or polynomial convergence or divergence\n",
      "        \n",
      "        -- abs(g) is:\n",
      "            > 1 for geometric convergence of rate 1/h**n\n",
      "            < 1 for geometric divergence of rate h**n\n",
      "            = 1 for polynomial convergence or divergence\n",
      "        \n",
      "            (g < 0 indicates an alternating series)\n",
      "        \n",
      "        -- p is:\n",
      "            > 1 for polynomial convergence of rate 1/n**h\n",
      "            <= 1 for polynomial divergence of rate n**(-h)\n",
      "    \n",
      "    check_target(expr, result, prec)\n",
      "    \n",
      "    chop_parts(value, prec)\n",
      "        Chop off tiny real or complex parts.\n",
      "    \n",
      "    complex_accuracy(result)\n",
      "        Returns relative accuracy of a complex number with given accuracies\n",
      "        for the real and imaginary parts. The relative accuracy is defined\n",
      "        in the complex norm sense as ||z|+|error|| / |z| where error\n",
      "        is equal to (real absolute error) + (imag absolute error)*i.\n",
      "        \n",
      "        The full expression for the (logarithmic) error can be approximated\n",
      "        easily by using the max norm to approximate the complex norm.\n",
      "        \n",
      "        In the worst case (re and im equal), this is wrong by a factor\n",
      "        sqrt(2), or by log2(sqrt(2)) = 0.5 bit.\n",
      "    \n",
      "    do_integral(expr, prec, options)\n",
      "    \n",
      "    evalf(x, prec, options)\n",
      "    \n",
      "    evalf_abs(expr, prec, options)\n",
      "    \n",
      "    evalf_add(v, prec, options)\n",
      "    \n",
      "    evalf_atan(v, prec, options)\n",
      "    \n",
      "    evalf_bernoulli(expr, prec, options)\n",
      "    \n",
      "    evalf_ceiling(expr, prec, options)\n",
      "    \n",
      "    evalf_floor(expr, prec, options)\n",
      "    \n",
      "    evalf_im(expr, prec, options)\n",
      "    \n",
      "    evalf_integral(expr, prec, options)\n",
      "    \n",
      "    evalf_log(expr, prec, options)\n",
      "    \n",
      "    evalf_mul(v, prec, options)\n",
      "    \n",
      "    evalf_piecewise(expr, prec, options)\n",
      "    \n",
      "    evalf_pow(v, prec, options)\n",
      "    \n",
      "    evalf_prod(expr, prec, options)\n",
      "    \n",
      "    evalf_re(expr, prec, options)\n",
      "    \n",
      "    evalf_subs(prec, subs)\n",
      "        Change all Float entries in `subs` to have precision prec.\n",
      "    \n",
      "    evalf_sum(expr, prec, options)\n",
      "    \n",
      "    evalf_symbol(x, prec, options)\n",
      "    \n",
      "    evalf_trig(v, prec, options)\n",
      "        This function handles sin and cos of complex arguments.\n",
      "        \n",
      "        TODO: should also handle tan of complex arguments.\n",
      "    \n",
      "    fastlog(x)\n",
      "        Fast approximation of log2(x) for an mpf value tuple x.\n",
      "        \n",
      "        Notes: Calculated as exponent + width of mantissa. This is an\n",
      "        approximation for two reasons: 1) it gives the ceil(log2(abs(x)))\n",
      "        value and 2) it is too high by 1 in the case that x is an exact\n",
      "        power of 2. Although this is easy to remedy by testing to see if\n",
      "        the odd mpf mantissa is 1 (indicating that one was dealing with\n",
      "        an exact power of 2) that would decrease the speed and is not\n",
      "        necessary as this is only being used as an approximation for the\n",
      "        number of bits in x. The correct return value could be written as\n",
      "        \"x[2] + (x[3] if x[1] != 1 else 0)\".\n",
      "            Since mpf tuples always have an odd mantissa, no check is done\n",
      "        to see if the mantissa is a multiple of 2 (in which case the\n",
      "        result would be too large by 1).\n",
      "        \n",
      "        Examples\n",
      "        ========\n",
      "        \n",
      "        >>> from sympy import log\n",
      "        >>> from sympy.core.evalf import fastlog, bitcount\n",
      "        >>> s, m, e = 0, 5, 1\n",
      "        >>> bc = bitcount(m)\n",
      "        >>> n = [1, -1][s]*m*2**e\n",
      "        >>> n, (log(n)/log(2)).evalf(2), fastlog((s, m, e, bc))\n",
      "        (10, 3.3, 4)\n",
      "    \n",
      "    finalize_complex(re, im, prec)\n",
      "    \n",
      "    from_man_exp = _mpmath_create(...)\n",
      "        _mpmath_create(...): helper function for mpmath.\n",
      "    \n",
      "    get_abs(expr, prec, options)\n",
      "    \n",
      "    get_complex_part(expr, no, prec, options)\n",
      "        no = 0 for real part, no = 1 for imaginary part\n",
      "    \n",
      "    get_integer_part(expr, no, options, return_ints=False)\n",
      "        With no = 1, computes ceiling(expr)\n",
      "        With no = -1, computes floor(expr)\n",
      "        \n",
      "        Note: this function either gives the exact result or signals failure.\n",
      "    \n",
      "    hypsum(expr, n, start, prec)\n",
      "        Sum a rapidly convergent infinite hypergeometric series with\n",
      "        given general term, e.g. e = hypsum(1/factorial(n), n). The\n",
      "        quotient between successive terms must be a quotient of integer\n",
      "        polynomials.\n",
      "    \n",
      "    iszero(mpf, scaled=False)\n",
      "    \n",
      "    mpmath_bitcount = bit_length(...)\n",
      "        x.bit_length() -> int\n",
      "        \n",
      "        Return the number of significant bits in the radix-2\n",
      "        representation of x. Note: mpz(0).bit_length() returns 0.\n",
      "    \n",
      "    normalize = _mpmath_normalize(...)\n",
      "        _mpmath_normalize(...): helper function for mpmath.\n",
      "    \n",
      "    pure_complex(v, or_real=False)\n",
      "        Return a and b if v matches a + I*b where b is not zero and\n",
      "        a and b are Numbers, else None. If `or_real` is True then 0 will\n",
      "        be returned for `b` if `v` is a real number.\n",
      "        \n",
      "        >>> from sympy.core.evalf import pure_complex\n",
      "        >>> from sympy import sqrt, I, S\n",
      "        >>> a, b, surd = S(2), S(3), sqrt(2)\n",
      "        >>> pure_complex(a)\n",
      "        >>> pure_complex(a, or_real=True)\n",
      "        (2, 0)\n",
      "        >>> pure_complex(surd)\n",
      "        >>> pure_complex(a + b*I)\n",
      "        (2, 3)\n",
      "        >>> pure_complex(I)\n",
      "        (0, 1)\n",
      "    \n",
      "    scaled_zero(mag, sign=1)\n",
      "        Return an mpf representing a power of two with magnitude ``mag``\n",
      "        and -1 for precision. Or, if ``mag`` is a scaled_zero tuple, then just\n",
      "        remove the sign from within the list that it was initially wrapped\n",
      "        in.\n",
      "        \n",
      "        Examples\n",
      "        ========\n",
      "        \n",
      "        >>> from sympy.core.evalf import scaled_zero\n",
      "        >>> from sympy import Float\n",
      "        >>> z, p = scaled_zero(100)\n",
      "        >>> z, p\n",
      "        (([0], 1, 100, 1), -1)\n",
      "        >>> ok = scaled_zero(z)\n",
      "        >>> ok\n",
      "        (0, 1, 100, 1)\n",
      "        >>> Float(ok)\n",
      "        1.26765060022823e+30\n",
      "        >>> Float(ok, p)\n",
      "        0.e+30\n",
      "        >>> ok, p = scaled_zero(100, -1)\n",
      "        >>> Float(scaled_zero(ok), p)\n",
      "        -0.e+30\n",
      "\n",
      "DATA\n",
      "    DEFAULT_MAXPREC = 333\n",
      "    INF = inf\n",
      "    LG10 = 3.3219280948873626\n",
      "    MINUS_INF = -inf\n",
      "    S = S\n",
      "    SYMPY_INTS = (<class 'int'>, <class 'mpz'>)\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    evalf_table = {<class 'sympy.core.numbers.Zero'>: <function _create_ev...\n",
      "    fhalf = (0, mpz(1), -1, 1)\n",
      "    fnan = (0, mpz(0), -123, -1)\n",
      "    fnone = (1, mpz(1), 0, 1)\n",
      "    fone = (0, mpz(1), 0, 1)\n",
      "    fzero = (0, mpz(0), 0, 0)\n",
      "    mp = <mpmath.ctx_mp.MPContext object>\n",
      "    mpmath_inf = mpf('+inf')\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    rnd = 'n'\n",
      "    round_nearest = 'n'\n",
      "\n",
      "FILE\n",
      "    /Users/alexanderbrandon-bravo/opt/anaconda3/lib/python3.7/site-packages/sympy/core/evalf.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sym.evalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eval_Array_From_Expression(Input_Value_Array, Symbol_Variable, Symbolic_Expression):\n",
    "    \n",
    "    try:\n",
    "        raise\n",
    "        Eval_Func = sym.lambdify(Symbol_Variable, Symbolic_Expression)\n",
    "        Result_Array = Eval_Func(Input_Value_Array)\n",
    "        if len(Result_Array) != len(Input_Value_Array):\n",
    "            raise\n",
    "    except:\n",
    "        Result_Array = np.array([])\n",
    "        # Both arrays and tensors have a method flatten() meaning by chance the same statement works for both.\n",
    "        for Input_Value in Input_Value_Array.flatten():\n",
    "            Result_Array = np.append(Result_Array, float(Symbolic_Expression.evalf(subs={Symbol_Variable: Input_Value})))\n",
    "        \n",
    "        Result_Array = Result_Array.reshape(Input_Value_Array.shape)\n",
    "        \n",
    "        if type(Input_Value_Array) is torch.Tensor:\n",
    "            Result_Array = torch.tensor(Result_Array)\n",
    "    \n",
    "    return Result_Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4]).view((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Eval_Array_From_Expression(x, t, sym.sin(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8415],\n",
       "        [ 0.9093],\n",
       "        [ 0.1411],\n",
       "        [-0.7568]], dtype=torch.float64)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_need_overide(sparsity_mask_trial, original_diff_order):\n",
    "    Index_Gap = original_diff_order+1\n",
    "    \n",
    "    #First check zeroth and first derivatives are present. In no model is there ever the situation where either of these should  be removed, except for a single spring\n",
    "    for coeff_index in [0, Index_Gap-1, Index_Gap]:\n",
    "        if not coeff_index in sparsity_mask_trial:\n",
    "            return True\n",
    "    \n",
    "    #Next check if these 3 are the only remaining, in which case no more can be removed\n",
    "    if len(sparsity_mask_trial) == 3:\n",
    "        return False\n",
    "    \n",
    "    #Next check if all pairs are like\n",
    "    for coeff_index in range(1, original_diff_order):\n",
    "        if (coeff_index in sparsity_mask_trial) != (coeff_index+Index_Gap in sparsity_mask_trial):\n",
    "            return True\n",
    "    \n",
    "    #Next check that no derivatives skipped\n",
    "    Expected_State = False\n",
    "    for coeff_index in range(1, original_diff_order):\n",
    "        if (coeff_index in sparsity_mask_trial) == Expected_State:\n",
    "            if Expected_State == True:\n",
    "                return True\n",
    "            \n",
    "            Expected_State = True\n",
    "                \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 in\n",
      "2 in\n",
      "3 in\n",
      "3 out\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_need_overide(torch.tensor([0, 2, 3, 4]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [(1,2,3), (4,5,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (4, 5, 6)]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = zip(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x829d45370>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x829d45370>\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [10,40]\n",
    "b = [20,50]\n",
    "c = [30,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zip(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x829c4e7d0>"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, e, f = zip(*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 30) (40, 50, 60)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-443-0df94d8b06dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "l1, l2 = print(*z)\n",
    "print(*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = zip(list(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-455-36b7c9dfc165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "a = zip(*[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 7) (2, 5, 8) (3, 6, 9)\n"
     ]
    }
   ],
   "source": [
    "print(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(*zip([1],[2],[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = zip(*[(1,2,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x82ad03320>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (2,) (3,)\n"
     ]
    }
   ],
   "source": [
    "print(*r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = zip((1,2,3), (4,5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_0, E_1, E_2, Eta_1, Eta_2 = sym.symbols('E_0,E_1,E_2,Eta_1,Eta_2', real=True, positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eps, Sig = sym.symbols('epsilon,sigma', real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\epsilon$"
      ],
      "text/plain": [
       "epsilon"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sym.symbols('t', real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "LHS = E_1*(E_2*Eps + Eta_2*sym.Derivative(Eps, t)) + Eta_1*sym.Derivative(E_2*Eps + Eta_2*sym.Derivative(Eps, t), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle E_{1} \\left(E_{2} Eps + H_{2} \\frac{d}{d t} Eps\\right) + H_{1} \\frac{\\partial}{\\partial t} \\left(E_{2} Eps + H_{2} \\frac{d}{d t} Eps\\right)$"
      ],
      "text/plain": [
       "E_1*(E_2*Eps + Eta_2*Derivative(Eps, t)) + Eta_1*Derivative(E_2*Eps + Eta_2*Derivative(Eps, t), t)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{d}{d t} Eps$"
      ],
      "text/plain": [
       "Derivative(Eps, t)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.Derivative(Eps, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "RHS = Sig*(1/E_0 + 1/(E_1 + Eta_1*sym.Derivative(1, t)) + 1/(E_2 + Eta_2*sym.Derivative(1, t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle Eps$"
      ],
      "text/plain": [
       "Eps"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle Sig \\left(\\frac{1}{E_{2} + H_{2} \\frac{d}{d t} 1} + \\frac{1}{E_{1} + H_{1} \\frac{d}{d t} 1} + \\frac{1}{E_{0}}\\right)$"
      ],
      "text/plain": [
       "Sig*(1/(E_2 + Eta_2*Derivative(1, t)) + 1/(E_1 + Eta_1*Derivative(1, t)) + 1/E_0)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=sym.symbols('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = dt*dt*dt*Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle Sig dt^{3}$"
      ],
      "text/plain": [
       "Sig*dt**3"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = expr.subs((Sig*dt**3), sym.Derivative(Sig, t,t,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems good but remember, when looping need to START from teh HIGHEST deriv otherwise dt\\*Sig will be replaced even when dt^2\\*Sig is present etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{d^{3}}{d t^{3}} Sig$"
      ],
      "text/plain": [
       "Derivative(Sig, (t, 3))"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.,2.,3.,4.,5.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  4.,  6.,  8., 10.])"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  4.,  6.,  8., 10.])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelvin_sym_sum(order):\n",
    "    \n",
    "    E_Syms = [sym.symbols('E_'+str(Branch_Index), real=True, negative=False) for Branch_Index in range(1, order+1)]\n",
    "    Eta_Syms = [sym.symbols('eta_'+str(Branch_Index), real=True, negative=False) for Branch_Index in range(1, order+1)]\n",
    "    \n",
    "    all_syms = E_Syms + Eta_Syms\n",
    "    \n",
    "    dt = sym.symbols('dt')\n",
    "    \n",
    "    Expression = sym.S(0)\n",
    "    for Branch_Index in range(len(E_Syms)):\n",
    "        Expression += 1/(E_Syms[Branch_Index] + Eta_Syms[Branch_Index]*dt)\n",
    "        \n",
    "    return Expression, all_syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelvin_coeff_expressions(coeff_count):\n",
    "    \n",
    "    order = coeff_count // 2\n",
    "    \n",
    "    eps, sig = sym.symbols('epsilon,sigma', real=True)\n",
    "    E_0 = sym.symbols('E_0', real=True, negative=False)\n",
    "    \n",
    "    #Create and organise Kelvin general equation\n",
    "    summation, model_params_list = kelvin_sym_sum(order)\n",
    "    model_params_list = [E_0] + model_params_list\n",
    "    RHS = (1/E_0 + summation)*sig\n",
    "    RHS = sym.together(RHS)\n",
    "    RHS, denom = sym.fraction(RHS)\n",
    "    \n",
    "    full_expression = RHS - eps*denom\n",
    "    \n",
    "    #find coeffs - prep\n",
    "    expanded = sym.expand(full_expression)\n",
    "    dt = sym.symbols('dt')\n",
    "    \n",
    "    #Strain coeffs\n",
    "    coeff_expressions_list = [-expanded.coeff(eps, 1).coeff(dt, 0)]\n",
    "    for strain_order in range(2, order+1):\n",
    "        coeff_expressions_list += [-expanded.coeff(eps, 1).coeff(dt, strain_order)]\n",
    "        \n",
    "    #Stress coeffs\n",
    "    for stress_order in range(order+1):\n",
    "        coeff_expressions_list += [expanded.coeff(sig, 1).coeff(dt, stress_order)]\n",
    "    \n",
    "    return coeff_expressions_list, model_params_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[E_0*E_1*E_2,\n",
       " E_0*eta_1*eta_2,\n",
       " E_0*E_1 + E_0*E_2 + E_1*E_2,\n",
       " E_0*eta_1 + E_0*eta_2 + E_1*eta_2 + E_2*eta_1,\n",
       " eta_1*eta_2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ces, model_params_list = kelvin_coeff_expressions(5)\n",
    "ces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[E_0, E_1, E_2, eta_1, eta_2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equations_with_coeff_results(coeff_expression_list, coeff_value_list):\n",
    "    \n",
    "    coeff_equations_list = [coeff_expression - coeff_value for coeff_expression, coeff_value in zip(coeff_expression_list, coeff_value_list)]\n",
    "    \n",
    "    return coeff_equations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[E_0*E_1*E_2 - 1.0,\n",
       " E_0*eta_1*eta_2 - 10.0,\n",
       " E_0*E_1 + E_0*E_2 + E_1*E_2 - 3.0,\n",
       " E_0*eta_1 + E_0*eta_2 + E_1*eta_2 + E_2*eta_1 - 22.0,\n",
       " eta_1*eta_2 - 10.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_equations_list = equations_with_coeff_results(ces, torch.tensor([1,10,3,22,10]))\n",
    "coeff_equations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.00000000000000,\n",
       "  1.00000000000000,\n",
       "  1.00000000000000,\n",
       "  1.00000000000000,\n",
       "  10.0000000000000),\n",
       " (1.00000000000000,\n",
       "  1.00000000000000,\n",
       "  1.00000000000000,\n",
       "  10.0000000000000,\n",
       "  1.00000000000000)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_solutions_list = sym.solve(coeff_equations_list, model_params_list)\n",
    "param_solutions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eps = sym.symbols('epsilon', real=True)\n",
    "LHS = Eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{1}{E_{2} + dt \\eta_{2}} + \\frac{1}{E_{1} + dt \\eta_{1}}$"
      ],
      "text/plain": [
       "1/(E_2 + dt*eta_2) + 1/(E_1 + dt*eta_1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loop_Result, params = kelvin_sym_sum(2)\n",
    "Loop_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sigma \\left(\\frac{1}{E_{2} + dt \\eta_{2}} + \\frac{1}{E_{1} + dt \\eta_{1}} + \\frac{1}{E_{0}}\\right)$"
      ],
      "text/plain": [
       "sigma*(1/(E_2 + dt*eta_2) + 1/(E_1 + dt*eta_1) + 1/E_0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sig = sym.symbols('sigma', real=True)\n",
    "E_0 = sym.symbols('E_0', real=True, negative=False)\n",
    "RHS = (1/E_0 + Loop_Result)*Sig\n",
    "RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\sigma \\left(E_{0} \\left(E_{1} + dt \\eta_{1}\\right) + E_{0} \\left(E_{2} + dt \\eta_{2}\\right) + \\left(E_{1} + dt \\eta_{1}\\right) \\left(E_{2} + dt \\eta_{2}\\right)\\right)}{E_{0} \\left(E_{1} + dt \\eta_{1}\\right) \\left(E_{2} + dt \\eta_{2}\\right)}$"
      ],
      "text/plain": [
       "sigma*(E_0*(E_1 + dt*eta_1) + E_0*(E_2 + dt*eta_2) + (E_1 + dt*eta_1)*(E_2 + dt*eta_2))/(E_0*(E_1 + dt*eta_1)*(E_2 + dt*eta_2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RHS = sym.together(RHS)\n",
    "RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sigma \\left(E_{0} \\left(E_{1} + dt \\eta_{1}\\right) + E_{0} \\left(E_{2} + dt \\eta_{2}\\right) + \\left(E_{1} + dt \\eta_{1}\\right) \\left(E_{2} + dt \\eta_{2}\\right)\\right)$"
      ],
      "text/plain": [
       "sigma*(E_0*(E_1 + dt*eta_1) + E_0*(E_2 + dt*eta_2) + (E_1 + dt*eta_1)*(E_2 + dt*eta_2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RHS, Denom = sym.fraction(RHS)\n",
    "RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle E_{0} \\left(E_{1} + dt \\eta_{1}\\right) \\left(E_{2} + dt \\eta_{2}\\right)$"
      ],
      "text/plain": [
       "E_0*(E_1 + dt*eta_1)*(E_2 + dt*eta_2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle E_{0} \\epsilon \\left(E_{1} + dt \\eta_{1}\\right) \\left(E_{2} + dt \\eta_{2}\\right)$"
      ],
      "text/plain": [
       "E_0*epsilon*(E_1 + dt*eta_1)*(E_2 + dt*eta_2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LHS = LHS*Denom\n",
    "LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - E_{0} \\epsilon \\left(E_{1} + dt \\eta_{1}\\right) \\left(E_{2} + dt \\eta_{2}\\right) + \\sigma \\left(E_{0} \\left(E_{1} + dt \\eta_{1}\\right) + E_{0} \\left(E_{2} + dt \\eta_{2}\\right) + \\left(E_{1} + dt \\eta_{1}\\right) \\left(E_{2} + dt \\eta_{2}\\right)\\right)$"
      ],
      "text/plain": [
       "-E_0*epsilon*(E_1 + dt*eta_1)*(E_2 + dt*eta_2) + sigma*(E_0*(E_1 + dt*eta_1) + E_0*(E_2 + dt*eta_2) + (E_1 + dt*eta_1)*(E_2 + dt*eta_2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Expr = RHS - LHS\n",
    "Final_Expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - E_{0} E_{1} E_{2} \\epsilon - E_{0} E_{1} dt \\epsilon \\eta_{2} + E_{0} E_{1} \\sigma - E_{0} E_{2} dt \\epsilon \\eta_{1} + E_{0} E_{2} \\sigma - E_{0} dt^{2} \\epsilon \\eta_{1} \\eta_{2} + E_{0} dt \\eta_{1} \\sigma + E_{0} dt \\eta_{2} \\sigma + E_{1} E_{2} \\sigma + E_{1} dt \\eta_{2} \\sigma + E_{2} dt \\eta_{1} \\sigma + dt^{2} \\eta_{1} \\eta_{2} \\sigma$"
      ],
      "text/plain": [
       "-E_0*E_1*E_2*epsilon - E_0*E_1*dt*epsilon*eta_2 + E_0*E_1*sigma - E_0*E_2*dt*epsilon*eta_1 + E_0*E_2*sigma - E_0*dt**2*epsilon*eta_1*eta_2 + E_0*dt*eta_1*sigma + E_0*dt*eta_2*sigma + E_1*E_2*sigma + E_1*dt*eta_2*sigma + E_2*dt*eta_1*sigma + dt**2*eta_1*eta_2*sigma"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded = sym.expand(Final_Expr)\n",
    "expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle E_{0} E_{1} \\eta_{2} + E_{0} E_{2} \\eta_{1}$"
      ],
      "text/plain": [
       "E_0*E_1*eta_2 + E_0*E_2*eta_1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = sym.symbols('dt')\n",
    "Strain_t_coeff_expr = -expanded.coeff(Eps, 1).coeff(dt, 1)\n",
    "Strain_t_coeff_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff00 = -expanded.coeff(Eps, 1).coeff(dt, 0) / Strain_t_coeff_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{E_{0} E_{1} E_{2}}{E_{0} E_{1} \\eta_{2} + E_{0} E_{2} \\eta_{1}}$"
      ],
      "text/plain": [
       "E_0*E_1*E_2/(E_0*E_1*eta_2 + E_0*E_2*eta_1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{E_{1} E_{2}}{E_{1} \\eta_{2} + E_{2} \\eta_{1}}$"
      ],
      "text/plain": [
       "E_1*E_2/(E_1*eta_2 + E_2*eta_1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff00_simple = sym.simplify(coeff00)\n",
    "coeff00_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{- E_{0} E_{1} E_{2} \\epsilon - E_{0} E_{1} dt \\epsilon \\eta_{2} + E_{0} E_{1} \\sigma - E_{0} E_{2} dt \\epsilon \\eta_{1} + E_{0} E_{2} \\sigma - E_{0} dt^{2} \\epsilon \\eta_{1} \\eta_{2} + E_{0} dt \\eta_{1} \\sigma + E_{0} dt \\eta_{2} \\sigma + E_{1} E_{2} \\sigma + E_{1} dt \\eta_{2} \\sigma + E_{2} dt \\eta_{1} \\sigma + dt^{2} \\eta_{1} \\eta_{2} \\sigma}{E_{0} E_{1} \\eta_{2} + E_{0} E_{2} \\eta_{1}}$"
      ],
      "text/plain": [
       "(-E_0*E_1*E_2*epsilon - E_0*E_1*dt*epsilon*eta_2 + E_0*E_1*sigma - E_0*E_2*dt*epsilon*eta_1 + E_0*E_2*sigma - E_0*dt**2*epsilon*eta_1*eta_2 + E_0*dt*eta_1*sigma + E_0*dt*eta_2*sigma + E_1*E_2*sigma + E_1*dt*eta_2*sigma + E_2*dt*eta_1*sigma + dt**2*eta_1*eta_2*sigma)/(E_0*E_1*eta_2 + E_0*E_2*eta_1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded /= Strain_t_coeff_expr\n",
    "expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{- E_{0} E_{1} E_{2} \\epsilon - E_{0} E_{1} dt \\epsilon \\eta_{2} + E_{0} E_{1} \\sigma - E_{0} E_{2} dt \\epsilon \\eta_{1} + E_{0} E_{2} \\sigma - E_{0} dt^{2} \\epsilon \\eta_{1} \\eta_{2} + E_{0} dt \\eta_{1} \\sigma + E_{0} dt \\eta_{2} \\sigma + E_{1} E_{2} \\sigma + E_{1} dt \\eta_{2} \\sigma + E_{2} dt \\eta_{1} \\sigma + dt^{2} \\eta_{1} \\eta_{2} \\sigma}{E_{0} \\left(E_{1} \\eta_{2} + E_{2} \\eta_{1}\\right)}$"
      ],
      "text/plain": [
       "(-E_0*E_1*E_2*epsilon - E_0*E_1*dt*epsilon*eta_2 + E_0*E_1*sigma - E_0*E_2*dt*epsilon*eta_1 + E_0*E_2*sigma - E_0*dt**2*epsilon*eta_1*eta_2 + E_0*dt*eta_1*sigma + E_0*dt*eta_2*sigma + E_1*E_2*sigma + E_1*dt*eta_2*sigma + E_2*dt*eta_1*sigma + dt**2*eta_1*eta_2*sigma)/(E_0*(E_1*eta_2 + E_2*eta_1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = sym.simplify(expanded)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0$"
      ],
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded.coeff(Eps, 1).coeff(dt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,2,3]\n",
    "y=[4,5,6]\n",
    "z = x+y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.0$"
      ],
      "text/plain": [
       "3.00000000000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z=sym.symbols('x,y,z')\n",
    "coeff_expression = x+y\n",
    "coeff_expression.evalf(subs={x: 1, y: 2, z: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x + y$"
      ],
      "text/plain": [
       "x + y"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z=sym.symbols('x,y,z')\n",
    "coeff_expression = x+y\n",
    "coeff_expression.evalf(subs={x: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3$"
      ],
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z=sym.symbols('x,y,z')\n",
    "coeff_expression = x+y\n",
    "coeff_expression.subs(zip([x,y,z], [1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "import Documents.GitHub.DeePyMoD_torch_AlexVersion.src.deepymod_torch.VE_params as VE_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1/20, 1/10, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_mods = [1,1]\n",
    "viscs = [20]\n",
    "coeffs = VE_params.coeffs_from_model_params(E_mods, viscs)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0909, 0.9091, 0.2727, 2.0000, 0.9091], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.tensor(coeffs, dtype=torch.float32, requires_grad=True)\n",
    "#output = coeffs\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1.00000000000000,\n",
       "   1.00000000993411,\n",
       "   0.999999900658933,\n",
       "   1.00000004304780,\n",
       "   9.99999897347564)],\n",
       " [E_0, E_1, E_2, eta_1, eta_2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VE_params.model_params_from_coeffs(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621928620057038"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method shuffle in module random:\n",
      "\n",
      "shuffle(x, random=None) method of random.Random instance\n",
      "    Shuffle list x in place, and return None.\n",
      "    \n",
      "    Optional argument random is a 0-argument function returning a\n",
      "    random float in [0.0, 1.0); if it is the default None, the\n",
      "    standard random.random will be used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rn.shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([1,2,3]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([1,2,3]).reshape(-1,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([1,2,3,4,5,6,7,8,9]).reshape(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 6],\n",
       "       [7, 8, 9],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function permutation:\n",
      "\n",
      "permutation(...) method of numpy.random.mtrand.RandomState instance\n",
      "    permutation(x)\n",
      "    \n",
      "    Randomly permute a sequence, or return a permuted range.\n",
      "    \n",
      "    If `x` is a multi-dimensional array, it is only shuffled along its\n",
      "    first index.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : int or array_like\n",
      "        If `x` is an integer, randomly permute ``np.arange(x)``.\n",
      "        If `x` is an array, make a copy and shuffle the elements\n",
      "        randomly.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Permuted sequence or array range.\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.random.permutation(10)\n",
      "    array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random\n",
      "    \n",
      "    >>> np.random.permutation([1, 4, 9, 12, 15])\n",
      "    array([15,  1,  9,  4, 12]) # random\n",
      "    \n",
      "    >>> arr = np.arange(9).reshape((3, 3))\n",
      "    >>> np.random.permutation(arr)\n",
      "    array([[6, 7, 8], # random\n",
      "           [0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.random.permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50%50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function std in module numpy:\n",
      "\n",
      "std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>)\n",
      "    Compute the standard deviation along the specified axis.\n",
      "    \n",
      "    Returns the standard deviation, a measure of the spread of a distribution,\n",
      "    of the array elements. The standard deviation is computed for the\n",
      "    flattened array by default, otherwise over the specified axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Calculate the standard deviation of these values.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which the standard deviation is computed. The\n",
      "        default is to compute the standard deviation of the flattened array.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If this is a tuple of ints, a standard deviation is performed over\n",
      "        multiple axes, instead of a single axis or all the axes as before.\n",
      "    dtype : dtype, optional\n",
      "        Type to use in computing the standard deviation. For arrays of\n",
      "        integer type the default is float64, for arrays of float types it is\n",
      "        the same as the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output but the type (of the calculated\n",
      "        values) will be cast if necessary.\n",
      "    ddof : int, optional\n",
      "        Means Delta Degrees of Freedom.  The divisor used in calculations\n",
      "        is ``N - ddof``, where ``N`` represents the number of elements.\n",
      "        By default `ddof` is zero.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `std` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    standard_deviation : ndarray, see dtype parameter above.\n",
      "        If `out` is None, return a new array containing the standard deviation,\n",
      "        otherwise return a reference to the output array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    var, mean, nanmean, nanstd, nanvar\n",
      "    numpy.doc.ufuncs : Section \"Output arguments\"\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The standard deviation is the square root of the average of the squared\n",
      "    deviations from the mean, i.e., ``std = sqrt(mean(abs(x - x.mean())**2))``.\n",
      "    \n",
      "    The average squared deviation is normally calculated as\n",
      "    ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is specified,\n",
      "    the divisor ``N - ddof`` is used instead. In standard statistical\n",
      "    practice, ``ddof=1`` provides an unbiased estimator of the variance\n",
      "    of the infinite population. ``ddof=0`` provides a maximum likelihood\n",
      "    estimate of the variance for normally distributed variables. The\n",
      "    standard deviation computed in this function is the square root of\n",
      "    the estimated variance, so even with ``ddof=1``, it will not be an\n",
      "    unbiased estimate of the standard deviation per se.\n",
      "    \n",
      "    Note that, for complex numbers, `std` takes the absolute\n",
      "    value before squaring, so that the result is always real and nonnegative.\n",
      "    \n",
      "    For floating-point input, the *std* is computed using the same\n",
      "    precision the input has. Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for float32 (see example below).\n",
      "    Specifying a higher-accuracy accumulator using the `dtype` keyword can\n",
      "    alleviate this issue.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.std(a)\n",
      "    1.1180339887498949 # may vary\n",
      "    >>> np.std(a, axis=0)\n",
      "    array([1.,  1.])\n",
      "    >>> np.std(a, axis=1)\n",
      "    array([0.5,  0.5])\n",
      "    \n",
      "    In single precision, std() can be inaccurate:\n",
      "    \n",
      "    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n",
      "    >>> a[0, :] = 1.0\n",
      "    >>> a[1, :] = 0.1\n",
      "    >>> np.std(a)\n",
      "    0.45000005\n",
      "    \n",
      "    Computing the standard deviation in float64 is more accurate:\n",
      "    \n",
      "    >>> np.std(a, dtype=np.float64)\n",
      "    0.44999999925494177 # may vary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
