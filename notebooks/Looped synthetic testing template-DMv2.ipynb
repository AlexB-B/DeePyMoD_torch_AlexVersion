{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VE DG and DeepMoD testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append('../src')\n",
    "import deepymod_torch.VE_datagen as VE_datagen\n",
    "import deepymod_torch.VE_params as VE_params\n",
    "from deepymod_torch_v2.DeepMod import run_deepmod\n",
    "from deepymod_torch_v2.library_functions import mech_library\n",
    "\n",
    "np_seed = 2\n",
    "torch_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we set many parameters that define our problem. We define:\n",
    "- The model and model type (which is determined by input_type)\n",
    "- The shape, frequency and magnitude of the sinc input manipulation\n",
    "- The sampling rate from the data that will be generated\n",
    "\n",
    "I also here define any other parameters that need to be defined (for saving or the normal flow) but are not being used or tested for this particular use of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigated_param = 'Scanning for 2nd order viable GKM models strain input'\n",
    "\n",
    "input_type = 'Strain'\n",
    "# if input_type == 'Strain':\n",
    "#     model = 'GMM'\n",
    "# elif input_type == 'Stress':\n",
    "#     model = 'GKM'\n",
    "mech_model = 'GKM'\n",
    "\n",
    "# Define params as I imagine them. In this case, the GKM definitions.\n",
    "# Because we are using strain as input, these will be converted to GMM equivalents to model the correct system.\n",
    "E = [5e-4, 5e-4, 5e-4]\n",
    "eta = [2.2e-4, 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_desc = 'sigmoid sinc'\n",
    "omega = 2*np.pi # As I programmed 5 osc, with an f_AWG of 1 Hz, this makes f_prog 5 Hz.\n",
    "# This leaves omega as 10pi (2pi * f_AWG * f_prog)\n",
    "# I choose to aim for omega pi, so if f_AWG set to 0.1 Hz, this is accomplished.\n",
    "Amp = 7\n",
    "input_expr_1 = lambda t: Amp*np.sin(omega*t)/(omega*t)\n",
    "input_torch_lambda_1 = lambda t: Amp*torch.sin(omega*t)/(omega*t)\n",
    "\n",
    "def sigmoid_expr(max_value=1, h_shift=1, width=1):\n",
    "    return lambda t: max_value / (1 + h_shift*np.exp(-t/width))\n",
    "def sigmoid_torch_expr(max_value=1, h_shift=1, width=1):\n",
    "    return lambda t: max_value / (1 + h_shift*torch.exp(-t/width))\n",
    "width_val = 0.1\n",
    "shift_val = 1/(300*width_val)\n",
    "input_expr_2 = sigmoid_expr(h_shift=shift_val, width=width_val)\n",
    "input_torch_lambda_2 = sigmoid_torch_expr(h_shift=shift_val, width=width_val)\n",
    "\n",
    "# Multiplying 2 signals together\n",
    "input_expr = lambda t: input_expr_1(t) * input_expr_2(t)\n",
    "input_torch_lambda = lambda t: input_torch_lambda_1(t) * input_torch_lambda_2(t)\n",
    "\n",
    "number_of_samples = 1000\n",
    "noise_level = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate data, we need to choose where and when to evaluate the target data for a given manipulation. Below, we choose those time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = np.linspace(-5*np.pi/omega, 10*np.pi/omega, 5000).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_omega = 1.2\n",
    "time_sf = omega/scaled_omega\n",
    "scaled_time_array = time_array*time_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we configure DeepMoD. We configure:\n",
    "- The initial L1 regularisation penalty\n",
    "- The learning rate\n",
    "- The number of epochs at each stage of training\n",
    "- The size and shape of the network\n",
    "- The library function for calculating potential terms relevant to VE problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 0.05\n",
    "thresh_pc = lambda *args: percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_config = {'library_func': mech_library,\n",
    "                  'diff_order': 2,\n",
    "                  'coeff_sign': 'positive',\n",
    "                  'input_type': input_type}\n",
    "network_config = {'hidden_dim': 30}\n",
    "optim_config = {'lr_coeffs': 0.002,\n",
    "                'lambda': 10**-6,\n",
    "                'thresh_func': thresh_pc,\n",
    "                'PINN': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information for saving that doesn't change each loop...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = '../data/Results'\n",
    "first_subfolder = investigated_param.replace('.', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the values we wish to test.\n",
    "\n",
    "In this use of the notebook it is the value of the PyTorch random seed. The purpose is to investigate if DeepMoD is sensitive to this, does it discover different models given different starting initialisations. Aferwards will want to check if each model replicates essentially the same curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd viscosities\n",
    "param_vals_1 = np.geomspace(1e-3, 1e-3, num=1)\n",
    "param_vals_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the loop. In each iteration of the loop:\n",
    "\n",
    "- Parameter(s) of interest will be updated.\n",
    "- Data will be synthesised from the model and manipulation description.\n",
    "- The data will be prepared for DeepMoD injection\n",
    "- DeepMoD will try its best\n",
    "- The results will be organised and saved in a named folder.\n",
    "- The progress will be available in Tensorboard files also which will need to be manually dragged across after the loop is done (or during!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of tests are now (relevant only when looping 2 or more sets of values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tau_2_values)*len(noise_level_values)*number_of_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |      NA |\n",
      "     100000    100.00%               0s   6.47e-06   3.70e-06   2.76e-06   0.00e+00   0.00e+00 \n",
      "[Parameter containing:\n",
      "tensor([[0.1424],\n",
      "        [1.2284],\n",
      "        [0.2585],\n",
      "        [1.0747],\n",
      "        [0.7864]], requires_grad=True)]\n",
      "Saving results\n"
     ]
    }
   ],
   "source": [
    "for param_val in param_vals_1:\n",
    "    \n",
    "    print('Starting loop with parameter value:', param_val)\n",
    "    \n",
    "    # Update investigated parameter\n",
    "    eta[1] = param_val\n",
    "    \n",
    "    # reset randomised initialisation\n",
    "    np.random.seed(np_seed)\n",
    "    torch.manual_seed(torch_seed)\n",
    "\n",
    "    # DATA GENERATION\n",
    "    \n",
    "    # Update model\n",
    "    # Convert to the equivalent description of GMM which is what flow is forced to presume given input_type\n",
    "#     E, eta = VE_params.convert_between_models(E_GKM, eta_GKM, 'GKM')\n",
    "    print('Converted!')\n",
    "    \n",
    "    # Generate data using updated model\n",
    "#     strain_array, stress_array = VE_datagen.calculate_strain_stress(input_type, time_array, input_expr, E, eta, D_input_lambda=d_input_expr)\n",
    "    strain_array, stress_array = VE_datagen.calculate_int_diff_equation_initial(time_array, input_expr, E, eta, input_type, mech_model)\n",
    "    print('Calculated!')\n",
    "    \n",
    "    # Scale data\n",
    "    strain_sf = 1/np.max(abs(strain_array))\n",
    "    stress_sf = 1/np.max(abs(stress_array))\n",
    "    \n",
    "    if input_type == 'Strain':\n",
    "        scaled_input_torch_lambda = lambda t: strain_sf*input_torch_lambda(t/time_sf)\n",
    "        scaled_target_array = stress_array*stress_sf\n",
    "    elif input_type == 'Stress':\n",
    "        scaled_input_torch_lambda = lambda t: stress_sf*input_torch_lambda(t/time_sf)\n",
    "        scaled_target_array = strain_array*strain_sf\n",
    "    \n",
    "    # Add noise to value at each time point\n",
    "    noisy_target_array = scaled_target_array + noise_level * np.std(scaled_target_array) * np.random.standard_normal(scaled_target_array.shape)\n",
    "\n",
    "    # randomly sample\n",
    "    reordered_row_indices = np.random.permutation(scaled_time_array.size)\n",
    "    reduced_time_array = scaled_time_array[reordered_row_indices, :][:number_of_samples]\n",
    "    reduced_target_array = scaled_target_array[reordered_row_indices, :][:number_of_samples]\n",
    "\n",
    "    # DEEPMOD PREPARATION\n",
    "    # convert to tensors\n",
    "    time_tensor = torch.tensor(reduced_time_array, dtype=torch.float32, requires_grad=True)\n",
    "    target_tensor = torch.tensor(reduced_target_array, dtype=torch.float32)\n",
    "    \n",
    "    # load redefined torch expression for scaled input\n",
    "    library_config['input_expr'] = scaled_input_torch_lambda\n",
    "\n",
    "    \n",
    "    # DEEPMOD\n",
    "    # record start time for later transfer of tensorboard files to correct folders\n",
    "    # start time is always in GMT, regardless of system clock it seems....\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "    # run DeepMoD\n",
    "    print('Running DeepMoD')\n",
    "    model = run_deepmod(time_tensor, target_tensor, library_config, network_config, optim_config)\n",
    "    network = model.network\n",
    "    lstsq_guess_list = model.fit.initial_guess\n",
    "    sparse_coeff_vector_list_list = model.fit.coeff_vector_history\n",
    "    sparsity_mask_list_list = model.fit.sparsity_mask_history\n",
    "    print('Saving results')\n",
    "\n",
    "\n",
    "    # ORGANISING RESULTS\n",
    "    # Calculate unscaled expected coeffs.\n",
    "    unscaled_expected_coeffs = VE_params.coeffs_from_model_params(E, eta, mech_model)\n",
    "\n",
    "    # Scale true coeffs to ones we expect to be found after scaling.\n",
    "    # Convert list of expected coeffs to array for saving\n",
    "    scaled_expected_coeffs = VE_params.scaled_coeffs_from_true(unscaled_expected_coeffs, time_sf, strain_sf, stress_sf)\n",
    "    target_coeffs_array = np.array(scaled_expected_coeffs).reshape(-1,1)\n",
    "    \n",
    "    # recalculate prediction from trained network and convert to array for saving\n",
    "    prediction_array = np.array(network(time_tensor).detach().cpu())\n",
    "    \n",
    "    # convert pre-thresholding coeffs data to arrays for saving\n",
    "    pre_thresh_coeffs_array = np.array(sparse_coeff_vector_list_list[0][0].detach().cpu())\n",
    "#     pre_thresh_scaled_coeffs_array = np.array(scaled_coeff_vector_list_list[0][0].detach().cpu())\n",
    "\n",
    "    # convert final coeffs data to arrays for saving\n",
    "    final_coeffs_array = np.array(sparse_coeff_vector_list_list[-1][0].detach().cpu())\n",
    "#     final_scaled_coeffs_array = np.array(scaled_coeff_vector_list_list[-1][0].detach().cpu())\n",
    "    sparsity_mask_array = np.array(sparsity_mask_list_list[-1][0].cpu()).reshape(-1,1)\n",
    "\n",
    "    # group like data vectors together for saving\n",
    "    dg_series_data = np.concatenate((time_array, strain_array, stress_array), axis=1)\n",
    "    NN_series_data = np.concatenate((reduced_time_array, reduced_target_array, prediction_array), axis=1)\n",
    "#     pre_thresh_coeffs_data = np.concatenate((pre_thresh_coeffs_array, pre_thresh_scaled_coeffs_array), axis=1)\n",
    "#     final_coeffs_data = np.concatenate((final_coeffs_array, final_scaled_coeffs_array, sparsity_mask_array), axis=1)\n",
    "    pre_thresh_coeffs_data = pre_thresh_coeffs_array\n",
    "    final_coeffs_data = np.concatenate((final_coeffs_array, sparsity_mask_array), axis=1)\n",
    "    \n",
    "    # remove input library from dictionary\n",
    "    library_config.pop('input_theta')\n",
    "    \n",
    "    # Gather miscellaneous information into lists for saving\n",
    "    dg_info_list = ['Model: '+mech_model, f'E: {E}', f'eta: {eta}', 'Input: '+input_type, 'Desc: '+func_desc, f'omega: {omega}', f'Amp: {Amp}']\n",
    "    treatment_info_list = [f'noise_factor: {noise_level}', f'time_sf: {time_sf}', f'strain_sf: {strain_sf}', f'stress_sf: {stress_sf}']\n",
    "    config_dict_list = [f'optim: {optim_config}', f'network: {network_config}', f'library: {library_config}']\n",
    "    misc_list = ['date_stamp: '+dt_string, f'NumPy_seed: {np_seed}', f'Torch_seed: {torch_seed}']\n",
    "#     GKM_list = [f'E_GKM: {E_GKM}', f'eta_GKM: {eta_GKM}']\n",
    "\n",
    "    # SAVING RESULTS\n",
    "    # collect parameters to name folder for saving\n",
    "    second_subfolder = 'param_' + str(param_val).replace('.', '-')\n",
    "#     third_subfolder = 'noise_' + str(noise_level).replace('.', '-')\n",
    "#     fourth_subfolder = 'seed_' + str(seed_value)\n",
    "    foldername = parent_folder + '/' + first_subfolder + '/' + second_subfolder# + '/' + third_subfolder + '/' + fourth_subfolder\n",
    "\n",
    "    # make folder\n",
    "    if not os.path.isdir(foldername):\n",
    "        os.makedirs(foldername)\n",
    "\n",
    "    # save all array data\n",
    "    np.savetxt(foldername+'/DG_series_data.csv', dg_series_data, delimiter=',', header='Time, Strain, Stress')\n",
    "    np.savetxt(foldername+'/NN_series_data.csv', NN_series_data, delimiter=',', header='Time, Target, Prediction')\n",
    "    np.savetxt(foldername+'/expected_coeffs.csv', target_coeffs_array, delimiter=',', header='Expected_coeffs')\n",
    "#     np.savetxt(foldername+'/pre_thresh_coeffs_data.csv', pre_thresh_coeffs_data, delimiter=',', header='Trained_Coeffs, Scaled_Trained_Coeffs')\n",
    "#     np.savetxt(foldername+'/final_coeffs_data.csv', final_coeffs_data, delimiter=',', header='Trained_Coeffs, Scaled_Trained_Coeffs, Sparsity_Mask')\n",
    "    np.savetxt(foldername+'/pre_thresh_coeffs_data.csv', pre_thresh_coeffs_data, delimiter=',', header='Trained_Coeffs')\n",
    "    np.savetxt(foldername+'/final_coeffs_data.csv', final_coeffs_data, delimiter=',', header='Trained_Coeffs, Sparsity_Mask')\n",
    "    \n",
    "    # save all lists data\n",
    "    with open(foldername+'/DG_info_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in dg_info_list)\n",
    "        \n",
    "    with open(foldername+'/treatment_info_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in treatment_info_list)\n",
    "    \n",
    "    with open(foldername+'/config_dict_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in config_dict_list)\n",
    "    \n",
    "    with open(foldername+'/misc_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in misc_list)\n",
    "        \n",
    "#     with open(foldername+'/GKM_list.txt', 'w') as file:\n",
    "#         file.writelines(f'{line}\\n' for line in GKM_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
