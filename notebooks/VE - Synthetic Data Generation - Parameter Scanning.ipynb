{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viscoelastic multiple synthetic analyses template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a launchpad for testing *DeepMoD's* capabilities under a specified range of parameters for the problem of linear viscoelasticity and the Generalized Differential Model (GDM). The analysis is entirely based on the analysis fully explained in the notebook 'Example - VE - Synthetic Data Generation'. Here the focus is also on synthetic scenarios, where a manipulation is defined, the response simulated, and DeepMoD applied as an analysis tool to the results. The structure of this notebook is:\n",
    "\n",
    "1. 1 or more parameters are chosen to be varied, and the values to be scanned through are defined. The 'parameters' may be anything, from the definition of the manipulation, to the scaling applied to the data series, to the hyper-parameters of the optimization process.\n",
    "\n",
    "2. Given the above varying parameters, all preperation common to every test being conducted is worked through.\n",
    "\n",
    "3. Any parts of the process that is affected by the varied paramters is embedded into a loop, and this loop is run to perform teh full analysis as many times as necessary to work through all the values of the parameters being varied.\n",
    "\n",
    "Depending on the parameters varied, the relative sizes of steps 2 and 3 can vary hugely. In the default state of this notebook, **ALL** processing will be contained in step 3, with step 2 left blank and can be expanded at the discretion of future users. The exception to this is the definition of the library function which is core to the problem type, and not intended to be varied.\n",
    "\n",
    "No attempt will be made in this notebook to guide the reader through any parts that exist also in the notebook 'Example - VE - Synthetic Data Generation' however explanation will be made for any novel parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append('../src')\n",
    "import deepymod_torch.VE_datagen as VE_datagen\n",
    "import deepymod_torch.VE_params as VE_params\n",
    "from deepymod_torch.DeepMod import run_deepmod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting varied parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the values we wish to test. This must be defined as an iterable of some kind. For testing, the geometric progression generator from NumPy is recommended. The switch between these values will occur at the top of the loop for each test, and the integration of the value will depend on the value being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation_title = 'Synthetic Noise - solid paper example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_vals_1 = np.geomspace(np.sqrt(10)/100, 0.1, num=4)[-2:0:-1]\n",
    "param_vals_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common processing and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Move as much code here as possible to decrease computational cost. Any parts of the process unaffected by the varying parameters can be placed here.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as auto\n",
    "    \n",
    "def mech_library(inputs, **library_config):\n",
    "    '''\n",
    "    Library function for the problem of linear viscoelasticity. Calculates all derivatives up to a specified order for strain and stress.\n",
    "    The first derivative of strain is returned as the mandatory guiding side of the discovered model.\n",
    "    All terms calculated from strain in the returned library are multiplied by -1.\n",
    "    \n",
    "    Parameters\n",
    "        inputs: 2-tuple\n",
    "            A tuple of (prediction, data) where both are Nx1 tensors and gradients have been tracked from data to prediction.\n",
    "            The tensor, data, is the input to a neural network, whereas prediction is the output.\n",
    "        **library_config: kwargs packed into dict.\n",
    "            All additional configuration options. Mandatory is the inclusion of diff_order=int, input_type=string, and input_theta=2D tensor.\n",
    "            input_type must be either 'Strain' or 'Stress'\n",
    "            input_theta contains the library terms for the manipulation variable, including the first strain derivative if strain is the manipulation variable.\n",
    "            input_theta is therefore Nx(diff_order+1) always.\n",
    "            \n",
    "    Returns\n",
    "        [strain_t]: list\n",
    "            Contains a Nx1 tensor\n",
    "        theta: Nx(2*diff_order + 1) tensor\n",
    "    '''\n",
    "    \n",
    "    prediction, data = inputs\n",
    "    \n",
    "    # Load already calculated derivatives of manipulation variable\n",
    "    input_theta = library_config['input_theta']\n",
    "    if data.shape[0] == 1: # Swaps real input_theta out for dummy in initialisation pass.\n",
    "        input_theta = torch.ones((1, input_theta.shape[1]))\n",
    "    \n",
    "    # Automatic derivatives of response variable \n",
    "    output_derivs = auto_deriv(data, prediction, library_config['diff_order'])\n",
    "    output_theta = torch.cat((prediction, output_derivs), dim=1)\n",
    "    \n",
    "    # Identify the manipulation/response as Stress/Strain and organise into returned variables\n",
    "    if library_config['input_type'] == 'Strain':\n",
    "        strain = input_theta\n",
    "        stress = output_theta\n",
    "    else: # 'Stress'\n",
    "        strain = output_theta\n",
    "        stress = input_theta\n",
    "        \n",
    "    strain_t = strain[:, 1:2] # Extract the first time derivative of strain\n",
    "    strain = torch.cat((strain[:, 0:1], strain[:, 2:]), dim=1) # remove this before it gets put into theta\n",
    "    strain *= -1 # The negatives of all strain terms are included in the library so that all coefficients discovered should be positive.\n",
    "    theta = torch.cat((strain, stress), dim=1)\n",
    "    \n",
    "    return [strain_t], theta\n",
    "\n",
    "\n",
    "def auto_deriv(data, prediction, max_order):\n",
    "    '''\n",
    "    Computes all derivatives up to a specified order using automatic differentiation for a single input and a single output of a neural network.\n",
    "    If it is desired to calculate the derivatives of different predictions wrt different data, this function must be called multiple times.\n",
    "    \n",
    "    Parameters\n",
    "        data: Nx1 tensor\n",
    "            An input to the neural network.\n",
    "        prediction: Nx1 tensor\n",
    "            An output of the neural network.\n",
    "        max_order: float\n",
    "            Specifies the order up to which derivatives should be calculated.\n",
    "\n",
    "    Returns\n",
    "        derivs: Nxmax_order tensor\n",
    "            No column with the zeroth derivative (the prediction).\n",
    "    '''\n",
    "    \n",
    "    # First derivative builds off prediction.\n",
    "    derivs = auto.grad(prediction, data, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "    for _ in range(max_order-1):\n",
    "        # Higher derivatives chain derivatives from first derivative.\n",
    "        derivs = torch.cat((derivs, auto.grad(derivs[:, -1:], data, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]), dim=1)\n",
    "            \n",
    "    return derivs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration through tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_val_1 in param_vals_1:\n",
    "    \n",
    "    # Update investigated parameter\n",
    "    #### Here include lines to update varied attributes. ####\n",
    "    print('Starting loop with parameter value:', param_val_1)\n",
    "    noise_level = param_val_1\n",
    "    \n",
    "    # Reset randomised initialisation\n",
    "    np_seed = 2\n",
    "    torch_seed = 0\n",
    "    np.random.seed(np_seed)\n",
    "    torch.manual_seed(torch_seed)\n",
    "\n",
    "    \n",
    "    # DATA GENERATION\n",
    "    input_type = 'Strain'\n",
    "    \n",
    "    # Define model\n",
    "    mech_model = 'GMM'\n",
    "    E = 3*[1]\n",
    "    eta = [2.5, 0.5]\n",
    "    \n",
    "    # Define manipulation\n",
    "    func_desc = 'Sinc'\n",
    "    omega = 1\n",
    "    amp = 7\n",
    "    input_expr = lambda t: amp*np.sin(omega*t)/(omega*t)\n",
    "    d_input_expr = lambda t: (amp/t)*(np.cos(omega*t) - np.sin(omega*t)/(omega*t))\n",
    "    input_torch_lambda = lambda t: amp*torch.sin(omega*t)/(omega*t)\n",
    "    \n",
    "    dg_info_list = [f'Model: '+mech_model, f'E: {E}', f'eta: {eta}', 'Input: '+input_type, 'Desc: '+func_desc, f'omega: {omega}', f'Amp: {amp}']\n",
    "    \n",
    "    # Define time series\n",
    "    time_array = np.linspace(10**-10, 10*np.pi/omega, 5000).reshape(-1, 1)\n",
    "    \n",
    "    # Calculate viscoelastic data series\n",
    "    manipulation_array = input_expr(time_array)\n",
    "    response_array = VE_datagen.calculate_strain_stress(input_type, time_array, input_expr, d_input_expr, E, eta)\n",
    "    strain_array, stress_array = (manipulation_array, response_array) if input_type == 'Strain' else (response_array, manipulation_array)\n",
    "    \n",
    "    print('Data generated.')\n",
    "    \n",
    "    # DATA TREATMENT\n",
    "    # Scaling\n",
    "    time_sf = omega/1.2\n",
    "    strain_sf = 1/np.max(abs(strain_array))\n",
    "    stress_sf = 1/np.max(abs(stress_array))\n",
    "\n",
    "    scaled_time_array = time_array*time_sf\n",
    "    scaled_strain_array = strain_array*strain_sf\n",
    "    scaled_stress_array = stress_array*stress_sf\n",
    "    if input_type == 'Strain':\n",
    "        scaled_input_torch_lambda = lambda t: strain_sf*input_torch_lambda(t/time_sf)\n",
    "        scaled_target_array = scaled_stress_array\n",
    "    elif input_type == 'Stress':\n",
    "        scaled_input_torch_lambda = lambda t: stress_sf*input_torch_lambda(t/time_sf)\n",
    "        scaled_target_array = scaled_strain_array\n",
    "    \n",
    "    # Noise\n",
    "#     noise_level = 0 # This is the varied parameter in this example.\n",
    "    noisy_target_array = scaled_target_array + noise_level * np.std(scaled_target_array) * np.random.standard_normal(scaled_target_array.shape)\n",
    "\n",
    "    # Random sampling\n",
    "    number_of_samples = 1000\n",
    "    reordered_row_indices = np.random.permutation(scaled_time_array.size)\n",
    "    reduced_time_array = scaled_time_array[reordered_row_indices, :][:number_of_samples]\n",
    "    reduced_target_array = noisy_target_array[reordered_row_indices, :][:number_of_samples]\n",
    "\n",
    "    \n",
    "    # CONFIGURATION OF DEEPMOD\n",
    "    # Conversion to PyTorch tensors\n",
    "    time_tensor = torch.tensor(reduced_time_array, dtype=torch.float32, requires_grad=True)\n",
    "    target_tensor = torch.tensor(reduced_target_array, dtype=torch.float32)\n",
    "    \n",
    "    # Manipulation variable library advance calculation\n",
    "    library_diff_order = 3\n",
    "    input_data = scaled_input_torch_lambda(time_tensor)\n",
    "    input_derivs = auto_deriv(time_tensor, input_data, library_diff_order)\n",
    "    input_theta = torch.cat((input_data.detach(), input_derivs.detach()), dim=1)\n",
    "    \n",
    "    # Threshold definition\n",
    "    percent = 0.05\n",
    "    def thresh_pc(*args): # Keep as full function so that it can be pickled\n",
    "        return percent\n",
    "    \n",
    "    # Definition of configuration dictionaries\n",
    "    library_config = {'library_func': mech_library,\n",
    "                      'diff_order': library_diff_order,\n",
    "                      'coeff_sign': 'positive',\n",
    "                      'input_type': input_type,\n",
    "                      'input_theta': input_theta}\n",
    "    network_config = {'hidden_dim': 30} # Optional\n",
    "    optim_config = {'lr_coeffs': 0.002,\n",
    "                    'thresh_func': thresh_pc,\n",
    "                    'l1': 1e-06} # Optional\n",
    "    report_config = {'plot': True, 'print_interval': 2000} # Optional\n",
    "    \n",
    "    \n",
    "    # LAUNCHING DEEPMOD\n",
    "    print('Running DeepMoD...')\n",
    "    begin_timestamp = datetime.now() # Saves time stamp for beginning of training.\n",
    "    model = run_deepmod(time_tensor, target_tensor, library_config, network_config, optim_config, report_config) # Extra config dicts not supplied by default.\n",
    "\n",
    "\n",
    "    # ORGANISING RESULTS\n",
    "    print('Saving...')\n",
    "    \n",
    "    # Prediction arrays\n",
    "    prediction_tensor = model.network(time_tensor)\n",
    "    prediction_array = np.array(prediction_tensor.detach())\n",
    "    time_tensor_post = torch.tensor(scaled_time_array, dtype=torch.float32, requires_grad=True)\n",
    "    full_prediction_tensor = model.network(time_tensor_post)\n",
    "    full_prediction_array = np.array(full_prediction_tensor.detach())\n",
    "    \n",
    "    # Expected coeffs\n",
    "    unscaled_coeffs = VE_params.coeffs_from_model_params(E, eta, mech_model)\n",
    "    expected_coeffs = VE_params.scaled_coeffs_from_true(unscaled_coeffs, time_sf, strain_sf, stress_sf)\n",
    "    \n",
    "    # Coeffs arrays\n",
    "    sparse_coeff_vector_list_list = model.fit.coeff_vector_history\n",
    "    sparsity_mask_list_list = model.fit.sparsity_mask_history\n",
    "    \n",
    "    target_coeffs_array = np.array(expected_coeffs).reshape(-1,1)\n",
    "    pre_thresh_coeffs_array = np.array(sparse_coeff_vector_list_list[0][0].detach())\n",
    "    final_coeffs_array = np.array(sparse_coeff_vector_list_list[-1][0].detach())\n",
    "    sparsity_mask_array = np.array(sparsity_mask_list_list[-1][0]).reshape(-1,1)\n",
    "    unscaled_final_coeffs = VE_params.true_coeffs_from_scaled(final_coeffs_array, time_sf, strain_sf, stress_sf, mask=sparsity_mask_array, library_diff_order=library_diff_order)\n",
    "    true_coeffs_array = np.array(unscaled_final_coeffs).reshape(-1, 1)\n",
    "\n",
    "    # Group like data vectors together for saving\n",
    "    dg_series_data = np.concatenate((time_array, strain_array, stress_array), axis=1)\n",
    "    NN_series_data = np.concatenate((reduced_time_array, reduced_target_array, prediction_array), axis=1)\n",
    "    final_coeffs_data = np.concatenate((final_coeffs_array, true_coeffs_array, sparsity_mask_array), axis=1)\n",
    "    \n",
    "    # remove input library from dictionary\n",
    "    library_config.pop('input_theta', None)\n",
    "    \n",
    "    # Gather miscellaneous information into lists for saving\n",
    "    treatment_info_list = [f'noise_factor: {noise_level}', f'time_sf: {time_sf}', f'strain_sf: {strain_sf}', f'stress_sf: {stress_sf}']\n",
    "    config_dict_list = [f'library: {library_config}', f'network: {network_config}', f'optim: {optim_config}', f'report: {report_config}']\n",
    "    dt_string = begin_timestamp.strftime('%d/%m/%Y %H:%M:%S')\n",
    "    misc_list = ['date_stamp: '+dt_string, f'NumPy_seed: {np_seed}', f'Torch_seed: {torch_seed}']\n",
    "    \n",
    "    \n",
    "    # SAVING RESULTS\n",
    "    # Collect parameters to name folder for saving\n",
    "    parent_folder = '../data/Results/Synthetic/Scans/'\n",
    "    subfolder = f'{investigation_title}/{param_val_1}/'.replace('.', '-')\n",
    "    foldername = parent_folder + subfolder\n",
    "\n",
    "    # Make folder\n",
    "    if not os.path.isdir(foldername):\n",
    "        os.makedirs(foldername)\n",
    "\n",
    "    # Save all array data\n",
    "    np.savetxt(foldername+'/DG_series_data.csv', dg_series_data, delimiter=',', header='Time, Strain, Stress')\n",
    "    np.savetxt(foldername+'/NN_series_data.csv', NN_series_data, delimiter=',', header='Time, Target, Prediction')\n",
    "    np.savetxt(foldername+'/expected_coeffs.csv', target_coeffs_array, delimiter=',', header='Expected_coeffs')\n",
    "    np.savetxt(foldername+'/pre_thresh_coeffs_data.csv', pre_thresh_coeffs_array, delimiter=',', header='Trained_Coeffs')\n",
    "    np.savetxt(foldername+'/final_coeffs_data.csv', final_coeffs_data, delimiter=',', header='Trained_Coeffs, Unscaled, Sparsity_Mask')\n",
    "    np.savetxt(foldername+'/full_prediction.csv', full_prediction_array, delimiter=',', header='Full Prediction')\n",
    "    \n",
    "    # Save all lists data\n",
    "    with open(foldername+'/DG_info_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in dg_info_list)\n",
    "        \n",
    "    with open(foldername+'/treatment_info_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in treatment_info_list)\n",
    "    \n",
    "    with open(foldername+'/config_dict_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in config_dict_list)\n",
    "    \n",
    "    with open(foldername+'/misc_list.txt', 'w') as file:\n",
    "        file.writelines(f'{line}\\n' for line in misc_list)\n",
    "    \n",
    "    # Save model\n",
    "    with open(foldername+'/model.pickle', 'wb') as file:\n",
    "        pickle.dump(model, file) # Will fail on dump if using lambda funcs, will fail on load if normal funcs that are not redefined."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
