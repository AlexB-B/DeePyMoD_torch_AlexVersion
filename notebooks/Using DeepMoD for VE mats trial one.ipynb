{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viscolelastic Materials Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we Choose the model and other parameters for our data, and save this data for reference later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../src')\n",
    "import data.Generation.VE_DataGen_Functions as vedg\n",
    "from deepymod_torch.library_function import mech_library\n",
    "from deepymod_torch.DeepMod import DeepMoD\n",
    "from deepymod_torch.neural_net import deepmod_init, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Type = 'Strain'\n",
    "E = [1,1,1]\n",
    "Eta = [1.25,2.5]\n",
    "t = sp.symbols('t', real=True)\n",
    "Input_Function = sp.exp(-t) + sp.exp(-t/10) + sp.exp(-t/20)\n",
    "Input_Description = 'Three_e_Decays'\n",
    "Int_Type = 'Numerical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0 + 3.0*exp(-0.8*t) + 3.0*exp(-0.4*t), <function Stress_Strain_Master_Int.<locals>.<lambda> at 0x152c591320>)\n"
     ]
    }
   ],
   "source": [
    "Tuple_of_Expressions = vedg.Stress_Strain_Master_Int(Input_Type, E, Eta, Input_Function, Int_Type, t)\n",
    "print(Tuple_of_Expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = np.linspace(0.001, 50, 5000)\n",
    "\n",
    "title = ('Input: ' + Input_Description + ', ' + Input_Type + \n",
    "         '.\\nModel: E Mods ' + str(E) + ', Viscs ' + str(Eta))\n",
    "\n",
    "Strain_Array, Stress_Array = vedg.Eval_Graph_Strain_Stress(title, time, Input_Function, Tuple_of_Expressions, Input_Type, Int_Type, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vedg.save_stress_strain(time, Strain_Array, Stress_Array, '../data/StressStrain', Input_Type, Input_Description, E, Eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mostly use DeepMoD using default settings as we would for any other problems. the configuratiosn specific to this application come from knowledge we already have, namely:\n",
    "\n",
    "- We are going to use a customised $\\Theta$ that only ever computes the derivatives of stress and strain, never the squares, as we are looking solve a system where these are the only terms present. We are looking at a hybrid problem here where we aren't completely blindly exploring the system. We assume the data is stress/strain data and we assume our models for these materials are accurate so as to produce an accurate format for the equations describing their dynamic behaviour.\n",
    "\n",
    "- For this, we need to use a library function of a new design.\n",
    "\n",
    "- In this library function, we will ask PyTorch to compute derivatives for the output variable up to a couple of orders of differentiation beyond expectations, just to demonstrate teh DeepmoD both, finds the correct coefficients, but also removes terms that should not be present.\n",
    "\n",
    "- the library function will also contain the assumption that all coefficients on the input function are negative. this way, teh coefficients that DeepMoD shoudl find will all be positive, as all viscosties and elastic moduli are postive, so all sums and products of them are also, and this si what makes up the coefficient.\n",
    "\n",
    "- This will allow us to further tinker and ask the random initial values of teh coefficients to all be positive, getting round an issue with DeepMod getting stuck in local minima\n",
    "\n",
    "- The derivatives of teh input function can be calculated without the neural network, as teh functional form of this is know. These results are still built into the loss though, as part of the equation-regression term.\n",
    "\n",
    "- Additionalyl, the lambda paramter will be made small. in essence, we are not looking for a very sparse vector, so L1 regullarisation actually hinders the convergence process.\n",
    "\n",
    "- Additionally, the LHS of the equation is fixed to the time derivative of the input with coeff 1\n",
    "\n",
    "> Is it the time derivative of the input, or always strain!!!!!!\n",
    "\n",
    "Once DeepMoD has its coefficnets, the job is not done as the coefficients need to be traced back into E_Mods and Viscs. i am not yet sure how to do this but\n",
    "\n",
    "- there will be two stages. the first is developing teh expressions for coeff 1 is this combination, coeff 2 is that one etc, and then teh second stage is using these simultaneous expressions to instead right each paramter in terms of teh coeffs.\n",
    "\n",
    "- The first part is not trivial as the parameters that go into forming the coeffs will be different depending on how many parameters are genuinely present in the model. The number of derivatives that deepmod finds can be used to determine which set of equations are going to be used.\n",
    "\n",
    "- Either these equations can be hard coded or\n",
    "\n",
    "- A pattern can be identified so that once the number of parameters is known, a loop can be run to generate the expressions (However, this method is only weakly scalable as, although identifying a pattern would allow easy identification of the full description of the coeffs for low order derivatives, the patterns would need to be worked out by hand for even higher derivatives leaving a) a lot of work by hand to allow the analysis to handle, let's say, 12th order derivatives and b) there will always be a ceiling determined arbitrarily by how high I have worked out the expressions for.) or\n",
    "\n",
    "- The root equation with sum could be looped and written in sympy, and the rearranged and sympy could be asked to find the expressions for coeffs of each term. the function `Differential` rather than `.diff` will be useful here to maintain the unsolved derivatives. Side note for coding: probably symbols can be placed into lists so that they do not have to be given unique names which could be tricky in a loop. -> ie `List_Syms[3] = sym.symbols('Tau'+Loop_Number, real=True)` etc.\n",
    "\n",
    "- The coeff on the LHS of the equation being fixed to 1 fixes all the other coeffs, so there is no ambiguity here.\n",
    "\n",
    "For the second part, using the coeffs to calculate each model parameter\n",
    "\n",
    "- I am hoping i can just use some function called solve or something in sympy to get the expressions for each aparamter in term so the coeffs, once the part 1 above is done. Indeed, this is possible on mathematica as demonstrated by the screenshot Remy sent by email.\n",
    "\n",
    "- Alternatively, they could be hard coded in if worked them out by hand......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra idea: The order of derivative should be teh same in both stress and strain. This is not a wild assumption. Perhaps teh loss can be further modified so as to penilise a situation where higher derivatives are being allowed in the 1st half of coeffs vs the other.\n",
    "\n",
    "Extra Idea: If the third derivative has been identified as being zero, all higher derivatives must also be zero. Remy suggested not harshly setting all to zero immediately, but removing the highest derivative and retraining, and then repeating, to see if lower derivatives are recovered.\n",
    "\n",
    "There is another consideration. There are two ways we can get the optimisation procedure to discover the right equation. The 'One Big Step' approach means modifying the loss function to be more and more aggressive. The other is a more iterative approach where the result can be critiqued, something changed, and the optimisation run again, such as the removal of the highest derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra note: need to think about the GKM vs GMM stuff. Essentially, teh creep and relaxation expressions used to generate the data have come from a GKM, not a GMM!. Presumably the results may differ slightly with a GMM, but at the same time, this leads to a direct final result, and the result should be the same if the two models are genuinely equivalent???\n",
    "\n",
    "In any case, the coefficents worked out will be different depending on whether we analyse in terms of a GKM or GMM. At leats at first glnce, would be an interesting test. certainly, the set of parameters making up each deduced coeff would be different, but perhaps, once the simultaneous equations are solved the resulting paramters are the same. ie, the coeff for the second deriv of stress will be described by different parameters sepending on the model, but a) the value for this coeff is model independant and b) the paremeters are model independant, its just that a different set of these parameters can be combined in a different way to get the same coeff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually getting on with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to reshape the data into a conveneint form. `vedg.save_stress_strain` does this also, so if importing the data this next step is unnecessary.\n",
    "\n",
    "For the purpose of running deepmod, we do not need the calculated dat for whatever the input is, as we will instead provide teh analytical expression. Understanding this is important as it explains why for around half of the terms in theta, we don't need to use the result of the NN to obtain the values, we can easily obtain them directly from the anayltical expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_Array = time.reshape(-1, 1)\n",
    "Stress_Array = Stress_Array.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../data/StressStrain/Strain Three_e_Decays E[1, 1, 1] V[1.25, 2.5].csv', delimiter=',')\n",
    "time_Array = data[:,[0]] # submitting the column index as a list preserves the idea that time_Array is a column,\n",
    "                            #otherwise it would default to a 1D array.\n",
    "Stress_Array = data[:,[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now the point where we might add **noise** and perform **random sampling** of the data. For now, in this first version of the notebook, we will skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to fully prepare the data for injection into PyTorch, we need to convert the arrays into tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_Tensor = torch.tensor(time_Array, dtype=torch.float32, requires_grad=True)\n",
    "Stress_Tensor = torch.tensor(Stress_Array, dtype=torch.float32)#, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by setting up DeepMoD as normal, as per Burgers example and then I will interogate for changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optim_config` is contains only a minor change. I have reduced the lambda variable to deemphasise the need for a sparse coeff_vector. I may do further tweaks later.\n",
    "\n",
    "`network config` contains the important change that there is only 1 input dimension in our problem, ie, only $t$. I have also reduced the size of the NN rather arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = {'lambda': 10**-6, 'max_iterations': 20000}\n",
    "network_config = {'input_dim': 1, 'hidden_dim': 15, 'layers': 3, 'output_dim': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The changes to `lib_config` is the business end. Poly order is a redundant variable as the single 'polynomial' term which would be stress or strain to the power of one, can be accounted for as the zeroth order derivative. There is no constant. An entirely new library 'type' function is created for our problem.\n",
    "\n",
    "Additionally, three new configuration paramters for our library dictionary are created. The first is the additional entry that will enforce the idea that all the initial guesses at the value of the coeffs (ksi vector) must be positive. The latter two allow the library to put the coefficients in the same order regardless of whether strain or stress was described by an analytical expression of our design, the analytical expression also being given as the final item in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepymod_torch.library_function import mech_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_config = {'type': mech_library, 'diff_order': 3, 'coeff_sign': 'positive', 'input_type': Input_Type, 'input_expr': Input_Function}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these configurations, in theory we should be able to run deepmod to interrogate the values of the coefficients of the derivatives in the general expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except, to break it down a little for this first run, let's actually pull out the code from DeepMoD and run bits step by step to better check for errors.\n",
    "\n",
    "First, we initialise the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepymod_torch.neural_net import deepmod_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New theta_from_input!\n"
     ]
    }
   ],
   "source": [
    "network, coeff_vector_list, sparsity_mask_list = deepmod_init(network_config, lib_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=15, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (7): Tanh()\n",
       "  (8): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "due to some changes made in the neural_net.py file, we notice the following has managed to take on board the need for these starting values to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.9892],\n",
       "         [1.3054],\n",
       "         [0.5081],\n",
       "         [0.4842],\n",
       "         [0.0099],\n",
       "         [0.9991],\n",
       "         [0.8547]], requires_grad=True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2, 3, 4, 5, 6])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our network and starting coeffs, let's try and train the network. This is the part one trainign which still includes the L1 term and contains all terms. As I specified a diff order of 5 earlier, this may be a little long to process...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepymod_torch.neural_net import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | Total loss | MSE | PI | L1 \n",
      "New theta_from_input!\n",
      "0 1.4E+00 1.4E+00 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "500 3.4E-01 3.4E-01 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "1000 1.4E-01 1.4E-01 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "1500 6.5E-02 6.5E-02 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "2000 3.2E-02 3.2E-02 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "2500 1.7E-02 1.7E-02 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "3000 8.5E-03 8.5E-03 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "3500 4.4E-03 4.4E-03 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "4000 2.3E-03 2.3E-03 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "4500 1.2E-03 1.2E-03 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "5000 6.3E-04 6.3E-04 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "5500 3.6E-04 3.6E-04 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "6000 1.9E-04 1.9E-04 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "6500 1.1E-04 1.1E-04 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "7000 6.6E-05 6.6E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "7500 4.3E-05 4.3E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "8000 3.0E-05 3.0E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "8500 2.2E-05 2.2E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "9000 1.7E-05 1.7E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "9500 1.4E-05 1.4E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "10000 1.1E-05 1.1E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "10500 9.7E-06 9.7E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "11000 8.4E-06 8.4E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "11500 7.4E-06 7.4E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "12000 7.5E-06 7.5E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "12500 6.7E-06 6.7E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "13000 5.5E-06 5.5E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "13500 5.1E-06 5.1E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "14000 4.8E-06 4.8E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "14500 4.5E-06 4.5E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "15000 4.3E-06 4.3E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "15500 4.1E-06 4.1E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "16000 3.9E-06 3.9E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "16500 3.7E-06 3.7E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "17000 3.6E-06 3.6E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "17500 3.5E-06 3.5E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "18000 3.3E-06 3.3E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "18500 3.2E-06 3.2E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "19000 3.2E-06 3.2E-06 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n",
      "19500 1.2E-05 1.2E-05 0.0E+00 0.0E+00\n",
      "tensor([[0.9892],\n",
      "        [1.3054],\n",
      "        [0.5081],\n",
      "        [0.4842],\n",
      "        [0.0099],\n",
      "        [0.9991],\n",
      "        [0.8547]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "time_deriv_list, theta, coeff_vector_list = train(time_Tensor, Stress_Tensor, network, coeff_vector_list, \n",
    "                                                  sparsity_mask_list, lib_config, optim_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepymod_torch.DeepMod import DeepMoD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_coeff_vector, sparsity_mask, network = DeepMoD(time_Tensor, Stress_Tensor, network_config, lib_config, optim_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
