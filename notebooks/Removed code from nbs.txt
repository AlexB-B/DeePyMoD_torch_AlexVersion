func_desc = 'Half Sinc'

#t = sym.symbols('t', real=True)
#input_expr = sym.sinc(omega*t)

# Wave packets
# omega = 2.5
# amp = 7
# input_expr, d_input_expr, input_torch_lambda = VE_datagen.wave_packet_lambdas_sum(omega, 0.5, 3, amp)

# step
# input_expr = lambda t: 1
# d_input_expr = lambda t: 0
# input_torch_lambda = lambda t: 1 + 0*t

# width_val = 0.1
# input_expr = sigmoid_expr(width=width_val)
# d_input_expr = d_sigmoid_expr(width=width_val)
# input_torch_lambda = sigmoid_torch_expr(width=width_val)

# sine
# omega = 1
# input_expr = lambda t: np.sin(omega*t)
# d_input_expr = lambda t: omega*np.cos(omega*t)
# input_torch_lambda = lambda t: torch.sin(omega*t)

# sinc
omega = 1
Amp = 7
input_expr = lambda t: Amp*np.sin(omega*t)/(omega*t)
d_input_expr = lambda t: (Amp/t)*(np.cos(omega*t) - np.sin(omega*t)/(omega*t))
input_torch_lambda = lambda t: Amp*torch.sin(omega*t)/(omega*t)

# sinc with hshift
# omega = 1
# shift = 6*np.pi
# input_expr = lambda t: np.sin(omega*(t - shift))/(omega*(t - shift))
# d_input_expr = lambda t: (1/(t - shift))*(np.cos(omega*(t - shift)) - np.sin(omega*(t - shift))/(omega*(t - shift)))
# input_torch_lambda = lambda t: torch.sin(omega*(t - shift))/(omega*(t - shift))

# sinc with vshift
# omega = np.pi
# neg_edge = -7.5 # for now is 3.75*T where T is 2*pi/omega. The 3.75 is chosen but could be any (n +- 0.25) where n is integer > 0.
# input_expr_no_shift = lambda t: np.sin(omega*t)/(omega*t)
# vshift = input_expr_no_shift(neg_edge)
# input_expr = lambda t: input_expr_no_shift(t) - vshift
# d_input_expr = lambda t: (1/t)*(np.cos(omega*t) - np.sin(omega*t)/(omega*t))
# input_torch_lambda = lambda t: torch.sin(omega*t)/(omega*t) - vshift

# sinc with both hshift and vshift
# omega = np.pi
# hshift = 7.5 # for now is 3.75*T where T is 2*pi/omega. The 3.75 is chosen but could be any (n +- 0.25) where n is integer > 0.
# input_expr_h_only = lambda t: np.sin(omega*(t - hshift))/(omega*(t - hshift))
# vshift = input_expr_h_only(0)
# input_expr = lambda t: input_expr_h_only(t) - vshift
# d_input_expr = lambda t: (1/(t - shift))*(np.cos(omega*(t - shift)) - np.sin(omega*(t - shift))/(omega*(t - shift)))
# input_torch_lambda = lambda t: torch.sin(omega*(t - hshift))/(omega*(t - hshift)) - vshift

# # soft step
# def sigmoid_expr(max_value=1, h_shift=0, width=1):
#     return lambda t: max_value / (1 + np.exp(-(t-h_shift)/width))

# def d_sigmoid_expr(max_value=1, h_shift=1, width=1): # h_shift is wrong
#     sig = sigmoid_expr(h_shift=h_shift, width=width)
#     return lambda t: (max_value/width) * sig(t) * (1 - sig(t))

# def sigmoid_torch_expr(max_value=1, h_shift=0, width=1):
#     return lambda t: max_value / (1 + torch.exp(-(t-h_shift)/width))

# width_val = 0.1
# shift_val = 5*(-2*np.pi/omega)
# input_expr_2 = sigmoid_expr(h_shift=shift_val, width=width_val)
# # d_input_expr_2 = d_sigmoid_expr(h_shift=shift_val, width=width_val)
# input_torch_lambda_2 = sigmoid_torch_expr(h_shift=shift_val, width=width_val)





# # Multiplying 2 signals together (product rule)
# input_expr = lambda t: input_expr_1(t) * input_expr_2(t)
# d_input_expr = lambda t: input_expr_1(t) * d_input_expr_2(t) + d_input_expr_1(t) * input_expr_2(t)
# input_torch_lambda = lambda t: input_torch_lambda_1(t) * input_torch_lambda_2(t)




# strain_array, stress_array = VE_datagen.calculate_int_diff_equation_initial(time_array, input_expr, E, eta, input_type, mech_model)




# The below code is a slight alternative version that produces data and targets that are still in chronological order.
# selected_row_indices = reordered_row_indices[:number_of_samples]
# selected_row_indices.sort()
# reduced_time_array = scaled_time_array[selected_row_indices, :]
# reduced_target_array = noisy_target_array[selected_row_indices, :]



lstsq_guess_list = model.fit.initial_guess



# Get time_deriv and theta
prediction_sc = model.network(time_tensor)
time_deriv_sc, theta_sc = model.library((prediction_sc, time_tensor))

# Get sparse theta
exp_diff_order_sc = len(eta)
strain_mask_sc = list(range(exp_diff_order_sc))
stress_mask_sc = list(range(library_diff_order, exp_diff_order_sc+library_diff_order+1))
sparsity_mask_sc = strain_mask_sc + stress_mask_sc
sparse_theta_sc = theta_sc[:, sparsity_mask_sc]

# Get exp coeffs
expected_coeffs_sc = torch.tensor(expected_coeffs, dtype=torch.float32).reshape(-1, 1)


scaling_single_vec(expected_coeffs_sc, sparse_theta_sc, time_deriv_sc[0])




bt_coeff_vector = sparse_coeff_vector_list_list[0][0].clone()
bt_sparsity_mask = sparsity_mask_list_list[0][0].clone()

response_recalc_bt = VE_datagen.calculate_int_diff_equation(time_tensor_post, full_prediction_tensor, scaled_input_expr, bt_coeff_vector, bt_sparsity_mask, library_diff_order, input_type)

# Alt finite difference method
bt_coeff_vector_array = np.array(bt_coeff_vector.detach())
if input_type == 'Strain':
    response_recalc_bt_fd = VE_datagen.calculate_finite_difference_diff_equation(scaled_time_array, scaled_strain_array, full_prediction_array, bt_coeff_vector_array, bt_sparsity_mask, library_diff_order, input_type)
else:
    response_recalc_bt_fd = VE_datagen.calculate_finite_difference_diff_equation(scaled_time_array, full_prediction_array, scaled_stress_array, bt_coeff_vector_array, bt_sparsity_mask, library_diff_order, input_type)
    
plt.plot(time_array.flatten(), full_prediction_array.flatten(), label='prediction')
plt.plot(time_array.flatten(), response_recalc_bt.flatten(), label='recalc', marker='.', markersize=1, linestyle='None')
plt.plot(time_array.flatten(), response_recalc_bt_fd.flatten(), label='recalc_fd', marker='.', markersize=1, linestyle='None')
plt.legend()




# Alt finite difference method
if input_type == 'Strain':
    response_recalc_at_fd = VE_datagen.calculate_finite_difference_diff_equation(scaled_time_array, scaled_strain_array, full_prediction_array, final_coeffs_array, sparsity_mask_array, library_diff_order, input_type)
else:
    response_recalc_at_fd = VE_datagen.calculate_finite_difference_diff_equation(scaled_time_array, full_prediction_array, scaled_stress_array, final_coeffs_array, sparsity_mask_array, library_diff_order, input_type)
    

plt.plot(time_array.flatten(), response_recalc_at_fd.flatten(), label='recalc_fd', marker='.', markersize=1, linestyle='None')
